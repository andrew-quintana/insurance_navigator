version: '3.8'

services:
  postgres:
    image: pgvector/pgvector:pg15
    environment:
      POSTGRES_DB: accessa_dev
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backend/scripts/migrations:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  api-server:
    build:
      context: .
      dockerfile: api/upload_pipeline/Dockerfile
    ports:
      - "8000:8000"
    environment:
      DATABASE_URL: postgresql://postgres:postgres@host.docker.internal:54322/postgres
      UPLOAD_PIPELINE_SUPABASE_URL: http://localhost:54321
      UPLOAD_PIPELINE_SUPABASE_ANON_KEY: ${SUPABASE_ANON_KEY}
      UPLOAD_PIPELINE_SUPABASE_SERVICE_ROLE_KEY: ${SUPABASE_SERVICE_ROLE_KEY}
      UPLOAD_PIPELINE_LLAMAPARSE_API_URL: http://mock-llamaparse:8001
      UPLOAD_PIPELINE_OPENAI_API_URL: http://mock-openai:8002
      UPLOAD_PIPELINE_ENVIRONMENT: development
      UPLOAD_PIPELINE_STORAGE_ENVIRONMENT: development
      UPLOAD_PIPELINE_STORAGE_URL: http://127.0.0.1:54321
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  enhanced-base-worker:
    build:
      context: .
      dockerfile: backend/workers/Dockerfile
    environment:
      DATABASE_URL: postgresql://postgres:postgres@host.docker.internal:54322/postgres
      SUPABASE_URL: http://localhost:54321
      SUPABASE_ANON_KEY: ${SUPABASE_JWT_TOKEN}
      SUPABASE_SERVICE_ROLE_KEY: ${SUPABASE_JWT_TOKEN}
      LLAMAPARSE_API_URL: https://api.cloud.llamaindex.ai
      OPENAI_API_URL: https://api.openai.com
      UPLOAD_PIPELINE_ENVIRONMENT: development
      UPLOAD_PIPELINE_STORAGE_ENVIRONMENT: development
      UPLOAD_PIPELINE_STORAGE_URL: http://127.0.0.1:54321
      # Enhanced worker configuration
      SERVICE_MODE: HYBRID
      LLAMAPARSE_API_KEY: ${LLAMAPARSE_API_KEY}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
    depends_on:
      postgres:
        condition: service_healthy
      api-server:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "from backend.workers.enhanced_base_worker import EnhancedBaseWorker; print('Enhanced worker import successful')"]
      interval: 30s
      timeout: 10s
      retries: 3

  mock-llamaparse:
    build:
      context: ./testing/mocks
      dockerfile: llamaparse.Dockerfile
    ports:
      - "8001:8001"
    environment:
      MOCK_LLAMAPARSE_DELAY: 2
      MOCK_LLAMAPARSE_FAILURE_RATE: 0.0
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  mock-openai:
    build:
      context: ./testing/mocks
      dockerfile: openai.Dockerfile
    ports:
      - "8002:8002"
    environment:
      MOCK_OPENAI_DELAY: 1
      MOCK_OPENAI_FAILURE_RATE: 0.0
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Local storage service for development
  local-storage:
    build:
      context: ./testing/mocks
      dockerfile: storage.Dockerfile
    ports:
      - "5001:5001"
    environment:
      MOCK_STORAGE_PORT: 5001
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  monitoring:
    build:
      context: ./backend/monitoring
      dockerfile: Dockerfile
    ports:
      - "3001:3000"
    environment:
      POSTGRES_URL: postgresql://postgres:postgres@postgres:5432/accessa_dev
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  postgres_data:

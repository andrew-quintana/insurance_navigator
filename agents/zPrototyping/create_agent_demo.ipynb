{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Unified create_agent() Function Demo\n",
        "\n",
        "This notebook demonstrates the comprehensive `create_agent()` function that combines all LangGraph utility features with toggleable options:\n",
        "\n",
        "## ğŸ›ï¸ Toggleable Features\n",
        "- **Message Patterns**: SystemMessage + HumanMessage vs combined prompts\n",
        "- **Structured Output**: LangChain pattern vs legacy validation vs plain text\n",
        "- **Prompt Composition**: File-based vs custom system messages\n",
        "- **Agent Patterns**: LangChain vs legacy vs mock modes\n",
        "- **Validation**: Pedantic vs lenient, with/without wrappers\n",
        "- **Output Options**: Raw output inclusion, validation details\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup and imports\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path('.').resolve().parent.parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Import our unified utility\n",
        "from langgraph_utils import create_agent, ExampleAgentOutput, ChainOfThoughtOutput\n",
        "\n",
        "# Try to import LangChain models\n",
        "try:\n",
        "    from langchain_anthropic import ChatAnthropic\n",
        "    llm = ChatAnthropic(model=\"claude-3-5-haiku-latest\", temperature=0.1)\n",
        "    print(\"âœ… LangChain LLM available\")\n",
        "except ImportError:\n",
        "    llm = None\n",
        "    print(\"âš ï¸ LangChain not available - using mock mode\")\n",
        "\n",
        "# Define custom schema for testing\n",
        "class HealthcareResponse(BaseModel):\n",
        "    \"\"\"Healthcare assistant response schema\"\"\"\n",
        "    response: str = Field(description=\"Main response to user\")\n",
        "    urgency: str = Field(description=\"Urgency level: low, medium, high\")\n",
        "    next_steps: List[str] = Field(description=\"Recommended next steps\")\n",
        "    confidence: float = Field(description=\"Confidence score\", ge=0.0, le=1.0)\n",
        "\n",
        "print(\"ğŸ›ï¸ Setup complete - ready to test create_agent() patterns\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. ğŸ† Recommended Pattern: LangChain Structured Output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. LangChain structured output (recommended pattern)\n",
        "print(\"=== ğŸ† LangChain Structured Pattern ===\")\n",
        "\n",
        "healthcare_agent = create_agent(\n",
        "    name=\"HealthcareAssistant\",\n",
        "    prompt_path=\"example_prompt.md\",\n",
        "    examples_path=\"example_examples.json\",\n",
        "    output_schema=HealthcareResponse,\n",
        "    llm=llm,\n",
        "    # LangChain defaults (all True)\n",
        "    use_langchain_pattern=True,\n",
        "    use_structured_output=True,\n",
        "    use_human_message=True,\n",
        "    use_system_message=True,\n",
        "    merge_examples=True\n",
        ")\n",
        "\n",
        "print(f\"âœ… Created: {healthcare_agent.__name__}\")\n",
        "print(f\"ğŸ“– Documentation: {healthcare_agent.__doc__[:200]}...\")\n",
        "\n",
        "# Test with healthcare query\n",
        "result = healthcare_agent(\"I need to find a cardiologist who takes my insurance\")\n",
        "print(f\"\\nğŸ¯ Result type: {type(result)}\")\n",
        "print(f\"ğŸ“ Response: {result.response[:100]}...\")\n",
        "print(f\"âš¡ Urgency: {result.urgency}\")\n",
        "print(f\"ğŸ“‹ Next steps: {len(result.next_steps)} items\")\n",
        "print(f\"ğŸ¯ Confidence: {result.confidence}\")\n",
        "\n",
        "print(\"\\nâœ… LangChain pattern returns Pydantic objects directly!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. ğŸ”§ Message Pattern Toggles\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Test different message patterns\n",
        "print(\"=== ğŸ”§ Message Pattern Variations ===\")\n",
        "\n",
        "# 2a. SystemMessage + HumanMessage (default)\n",
        "print(\"\\nğŸ“¨ Pattern A: SystemMessage + HumanMessage\")\n",
        "agent_a = create_agent(\n",
        "    name=\"MessagePatternA\",\n",
        "    custom_system_message=\"You are a helpful healthcare assistant.\",\n",
        "    output_schema=ExampleAgentOutput,\n",
        "    use_system_message=True,\n",
        "    use_human_message=True,\n",
        "    use_mock_mode=True\n",
        ")\n",
        "\n",
        "result_a = agent_a(\"Find me a doctor\")\n",
        "print(f\"Result: {type(result_a)} - {result_a.response[:60]}...\")\n",
        "\n",
        "# 2b. Combined message (no HumanMessage)\n",
        "print(\"\\nğŸ“¨ Pattern B: Combined Message (no HumanMessage)\")\n",
        "agent_b = create_agent(\n",
        "    name=\"MessagePatternB\",\n",
        "    custom_system_message=\"You are a helpful healthcare assistant.\",\n",
        "    output_schema=ExampleAgentOutput,\n",
        "    use_system_message=True,\n",
        "    use_human_message=False,  # Input appended to system message\n",
        "    use_mock_mode=True\n",
        ")\n",
        "\n",
        "result_b = agent_b(\"Find me a doctor\")\n",
        "print(f\"Result: {type(result_b)} - {result_b.response[:60]}...\")\n",
        "\n",
        "# 2c. Single prompt (no SystemMessage)\n",
        "print(\"\\nğŸ“¨ Pattern C: Single Prompt (no SystemMessage)\")\n",
        "agent_c = create_agent(\n",
        "    name=\"MessagePatternC\",\n",
        "    custom_system_message=\"You are a helpful healthcare assistant.\",\n",
        "    output_schema=ExampleAgentOutput,\n",
        "    use_system_message=False,  # Everything in one message\n",
        "    use_human_message=True,\n",
        "    use_mock_mode=True\n",
        ")\n",
        "\n",
        "result_c = agent_c(\"Find me a doctor\")\n",
        "print(f\"Result: {type(result_c)} - {result_c.response[:60]}...\")\n",
        "\n",
        "print(\"\\nâœ… All message patterns work with same interface!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. ğŸ“‹ Summary\n",
        "\n",
        "### âœ… What We Demonstrated\n",
        "\n",
        "The unified `create_agent()` function provides:\n",
        "\n",
        "#### ğŸ›ï¸ **Toggleable Features**\n",
        "- **Message Patterns**: SystemMessage + HumanMessage vs combined prompts\n",
        "- **Output Types**: Structured (Pydantic) vs plain text\n",
        "- **Agent Patterns**: LangChain vs legacy vs mock modes\n",
        "- **Prompt Sources**: File-based vs custom system messages\n",
        "- **Validation**: Lenient vs pedantic, with/without wrappers\n",
        "- **Debug Options**: Raw output inclusion, validation details\n",
        "\n",
        "#### ğŸ† **Recommended Usage**\n",
        "```python\n",
        "# Production-ready pattern\n",
        "agent = create_agent(\n",
        "    name=\"MyAgent\",\n",
        "    prompt_path=\"prompt.md\",\n",
        "    examples_path=\"examples.json\",\n",
        "    output_schema=MySchema,\n",
        "    llm=ChatOpenAI(model=\"gpt-4\")\n",
        ")\n",
        "result = agent(\"user query\")  # Returns MySchema object\n",
        "```\n",
        "\n",
        "#### ğŸ”§ **Development/Testing**\n",
        "```python\n",
        "# Mock mode for testing\n",
        "agent = create_agent(\n",
        "    name=\"TestAgent\",\n",
        "    custom_system_message=\"You are helpful.\",\n",
        "    output_schema=Schema,\n",
        "    use_mock_mode=True,\n",
        "    return_raw_output=True\n",
        ")\n",
        "```\n",
        "\n",
        "#### ğŸ¯ **Key Benefits**\n",
        "- **Unified Interface**: One function for all agent patterns\n",
        "- **Backward Compatible**: Supports legacy patterns\n",
        "- **Future-Proof**: Uses LangChain best practices by default\n",
        "- **Flexible**: All features can be toggled on/off\n",
        "- **Production Ready**: Proper error handling and validation\n",
        "- **Development Friendly**: Mock mode and debug options\n",
        "\n",
        "### ğŸš€ Next Steps\n",
        "- Use `create_agent()` for all new agent development\n",
        "- Migrate existing agents to this unified interface\n",
        "- Combine with LangGraph workflows for complex agent systems\n",
        "- Add custom schemas for domain-specific structured outputs\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

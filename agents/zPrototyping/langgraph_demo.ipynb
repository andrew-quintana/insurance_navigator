{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# LangGraph Utilities Demonstration\n",
        "\n",
        "This notebook demonstrates the comprehensive utility module for LangGraph agent development, including:\n",
        "\n",
        "1. üìÑ **Prompt Composition** - Merge prompts with examples and placeholders\n",
        "2. üß± **Structured Validation** - Validate agent outputs with Pydantic schemas\n",
        "3. üîç **Dynamic Agent Discovery** - Automatically discover and load agents\n",
        "4. üï∏Ô∏è **Workflow Construction** - Build and chain LangGraph workflows\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup and imports\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to Python path (go up 2 levels from agents/sandbox/)\n",
        "project_root = Path('.').resolve().parent.parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Import our utility module directly from this directory\n",
        "from langgraph_utils import *\n",
        "\n",
        "# Setup logging (disable workflow logging for cleaner output)\n",
        "setup_logging(level=\"INFO\", enable_workflow_logging=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. üìÑ Prompt Composition Utilities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discovered placeholders: ['service', 'input', 'examples', 'name']\n",
            "Merged prompt:\n",
            "\n",
            "Hello Alice, welcome to our Healthcare Navigator.\n",
            "\n",
            "Your request: I need help finding a doctor\n",
            "\n",
            "Examples:\n",
            "No examples provided\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 1.1 Basic prompt template management with placeholder discovery and merging\n",
        "template_text = \"\"\"\n",
        "Hello {{name}}, welcome to our {{service}}.\n",
        "\n",
        "Your request: {{input}}\n",
        "\n",
        "Examples:\n",
        "{{examples}}\n",
        "\"\"\"\n",
        "\n",
        "# Create template instance with required placeholders validation\n",
        "prompt_template = PromptTemplate(template_text, required_placeholders=['name', 'input'])\n",
        "\n",
        "# Show discovered placeholders from template parsing\n",
        "print(f\"Discovered placeholders: {prompt_template.discovered_placeholders}\")\n",
        "\n",
        "# Merge template with actual values\n",
        "merged = prompt_template.merge(\n",
        "    name=\"Alice\",\n",
        "    service=\"Healthcare Navigator\",\n",
        "    input=\"I need help finding a doctor\",\n",
        "    examples=\"No examples provided\"\n",
        ")\n",
        "\n",
        "# Display final merged template\n",
        "print(\"Merged prompt:\")\n",
        "print(merged)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 4 examples from JSON\n",
            "Converted to markdown (2866 characters)\n",
            "\n",
            "Final merged prompt (3691 characters):\n",
            "# Example Agent Prompt Template\n",
            "\n",
            "You are an intelligent healthcare assistant specializing in analyzing patient requests and providing helpful guidance.\n",
            "\n",
            "## Your Role\n",
            "You help patients understand their healthcare options and navigate insurance coverage questions.\n",
            "\n",
            "## Examples\n",
            "## Example 1\n",
            "**Input:**\n",
            "I need to find a dermatologist who takes my insurance\n",
            "\n",
            "**Output:**\n",
            "I can help you find a dermatologist that accepts your insurance. To provide the most accurate recommendations, I'll need to know your insurance plan details and preferred location. Here's what I recommend: 1) Check your insurance provider's website or app for an in-network provider directory, 2) Call your insurance company's customer service line, 3) Contact local dermatology practices directly to verify coverage. Would you like me to help you navigate any of these options?\n",
            "\n",
            "**Context:**\n",
            "confidence: 0.9\n",
            "metadata:\n",
            "  request_type: provider_search\n",
            "  urgency: medium\n",
            "  requires_followup: True\n",
            "\n",
            "## Example 2\n",
            "**Input:**\n",
            "What does my insurance cover for mental health services?\n",
            "\n",
            "**Output:**\n",
            "Mental health coverage varies by insurance plan, but most plans are required to cover mental health services under the Mental Health Parity Act. Typically covered services include therapy sessions, psychiatric consultations, and some medication management. To find your specific coverage details: 1) Review your Summary of Benefits and Coverage (SBC), 2) Log into your insurance portal, 3) Call the member services number on your insurance card. I can help you understand what to look for in your benefits information.\n",
            "\n",
            "**Context:**\n",
            "confidence: 0.85\n",
            "metadata:\n",
            "  request_type: coverage_inquiry\n",
            "  urgency: medium\n",
            "  requires_followup: True\n",
            "\n",
            "## Example 3\n",
            "**Input:**\n",
            "I'm having chest pain, should I go to the ER?\n",
            "\n",
            "**Output:**\n",
            "Chest pain can be a serious medical emergency. If you're experiencing severe chest pain, pain that radiates to your arm, jaw, or back, shortness of breath, nausea, or dizziness, you should call 911 or go to the emergency room immediately. Do not drive yourself - call for emergency medical services. If your symptoms are mild and you're unsure, you can also call your doctor's office or a nurse hotline for guidance. When in doubt, it's always better to seek immediate medical attention for chest pain.\n",
            "\n",
            "**Context:**\n",
            "confidence: 0.95\n",
            "metadata:\n",
            "  request_type: urgent_medical_advice\n",
            "  urgency: high\n",
            "  requires_followup: False\n",
            "\n",
            "## Example 4\n",
            "**Input:**\n",
            "How do I find a pediatrician for my newborn?\n",
            "\n",
            "**Output:**\n",
            "Finding the right pediatrician for your newborn is important for their ongoing health. Here's how to find one: 1) Get referrals from your OB/GYN, family doctor, or friends, 2) Check your insurance network for covered pediatricians, 3) Schedule meet-and-greet appointments before delivery if possible, 4) Consider factors like office location, hours, hospital affiliations, and communication style. Many pediatricians offer prenatal consultations to help you make this decision. Would you like help with any specific aspect of this search?\n",
            "\n",
            "**Context:**\n",
            "confidence: 0.88\n",
            "metadata:\n",
            "  request_type: provider_search\n",
            "  urgency: medium\n",
            "  requires_followup: True\n",
            "\n",
            "\n",
            "## Instructions\n",
            "1. Analyze the user's request carefully\n",
            "2. Determine the type of assistance needed\n",
            "3. Provide a helpful response with confidence score\n",
            "4. Include relevant metadata\n",
            "\n",
            "## User Input\n",
            "I'm looking for a pediatrician in my area who takes Medicaid\n",
            "\n",
            "## Response Format\n",
            "Please respond in JSON format with the following structure:\n",
            "```json\n",
            "{\n",
            "  \"response\": \"Your helpful response here\",\n",
            "  \"confidence\": 0.85,\n",
            "  \"metadata\": {\n",
            "    \"request_type\": \"type_of_request\",\n",
            "    \"urgency\": \"low|medium|high\",\n",
            "    \"requires_followup\": true/false\n",
            "  }\n",
            "}\n",
            "``` \n"
          ]
        }
      ],
      "source": [
        "# 1.2 File-based prompt and examples merging from external files\n",
        "# Load examples from JSON file and convert to structured data\n",
        "examples_data = load_examples_file(\"example_examples.json\")\n",
        "print(f\"Loaded {len(examples_data)} examples from JSON\")\n",
        "\n",
        "# Convert examples to markdown format for prompt integration\n",
        "examples_md = convert_examples_to_markdown(examples_data)\n",
        "print(f\"Converted to markdown ({len(examples_md)} characters)\")\n",
        "\n",
        "# Load base prompt template from markdown file\n",
        "prompt_content = load_prompt_file(\"example_prompt.md\")\n",
        "\n",
        "# Merge prompt template with examples and user input\n",
        "user_input = \"I'm looking for a pediatrician in my area who takes Medicaid\"\n",
        "merged_prompt = merge_prompt_with_examples(\n",
        "    prompt_path=\"example_prompt.md\",\n",
        "    examples_path=\"example_examples.json\", \n",
        "    user_input=user_input\n",
        ")\n",
        "\n",
        "# Show final merged prompt ready for LLM\n",
        "print(f\"\\nFinal merged prompt ({len(merged_prompt)} characters):\")\n",
        "print(merged_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. üß± Structured Output Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid data validation: True\n",
            "Response: I can help you find a doctor in your area.\n",
            "Confidence: 0.9\n",
            "\n",
            "Invalid data validation: False\n",
            "Validation error: Validation errors:\n",
            "  - Field 'confidence': Input should be less than or equal to 1\n",
            "\n",
            "Direct Pydantic validation type: <class 'langgraph_utils.ExampleAgentOutput'>\n",
            "Direct validation response: I can help you find a doctor in your area.\n"
          ]
        }
      ],
      "source": [
        "# 2.1 Structured validation with Pydantic schemas\n",
        "# Create validators with different modes for schema validation\n",
        "lenient_validator = create_validator(ExampleAgentOutput, pedantic=False)\n",
        "pedantic_validator = create_validator(ExampleAgentOutput, pedantic=True)\n",
        "\n",
        "# Test data - valid structure matching ExampleAgentOutput schema\n",
        "valid_data = {\n",
        "    \"response\": \"I can help you find a doctor in your area.\",\n",
        "    \"confidence\": 0.9,\n",
        "    \"metadata\": {\"urgency\": \"medium\"}\n",
        "}\n",
        "\n",
        "# Validate with lenient mode (allows extra fields)\n",
        "is_valid, validated, error = lenient_validator.validate(valid_data)\n",
        "print(f\"Valid data validation: {is_valid}\")\n",
        "if validated:\n",
        "    print(f\"Response: {validated.response}\")\n",
        "    print(f\"Confidence: {validated.confidence}\")\n",
        "\n",
        "# Test data with validation error (confidence out of bounds)\n",
        "invalid_data = {\n",
        "    \"response\": \"I can help you find a doctor.\",\n",
        "    \"confidence\": 1.5,  # Invalid: exceeds 1.0 limit\n",
        "    \"metadata\": {\"urgency\": \"high\"}\n",
        "}\n",
        "\n",
        "# Show validation failure and error handling\n",
        "is_valid, validated, error = lenient_validator.validate(invalid_data)\n",
        "print(f\"\\nInvalid data validation: {is_valid}\")\n",
        "if error:\n",
        "    print(f\"Validation error: {error}\")\n",
        "\n",
        "# Demonstrate LangChain's direct Pydantic validation approach\n",
        "direct_valid = ExampleAgentOutput.model_validate(valid_data)\n",
        "print(f\"\\nDirect Pydantic validation type: {type(direct_valid)}\")\n",
        "print(f\"Direct validation response: {direct_valid.response}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2.2 LangChain Structured Output with Message Patterns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-21 19:15:19,748 - langgraph_utils - INFO - Creating LangChain structured agent: HealthcareMessage\n",
            "2025-06-21 19:15:19,749 - langgraph_utils - INFO - Creating real LangChain agent with ChatAnthropic\n",
            "2025-06-21 19:15:26,403 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
            "2025-06-21 19:15:26,418 - langgraph_utils - INFO - Agent HealthcareMessage generated structured output: <class 'langgraph_utils.ExampleAgentOutput'>\n",
            "2025-06-21 19:15:26,418 - langgraph_utils - INFO - Creating LangChain structured agent: ReasoningMessage\n",
            "2025-06-21 19:15:26,419 - langgraph_utils - INFO - Creating real LangChain agent with ChatAnthropic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Healthcare agent result type: <class 'langgraph_utils.ExampleAgentOutput'>\n",
            "Response: I can help you find an orthopedic surgeon. To provide the most accurat...\n",
            "Confidence: 0.85\n",
            "Metadata: ['request_type', 'urgency', 'requires_followup']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-21 19:15:30,768 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
            "2025-06-21 19:15:30,774 - langgraph_utils - INFO - Agent ReasoningMessage generated structured output: <class 'langgraph_utils.ChainOfThoughtOutput'>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Reasoning agent result type: <class 'langgraph_utils.ChainOfThoughtOutput'>\n",
            "Thinking: Choosing the right insurance requires a comprehensive evalua...\n",
            "Conclusion: The ideal insurance plan balances comprehensive coverage, af...\n",
            "Reasoning steps: 8\n",
            "Confidence: 0.85\n"
          ]
        }
      ],
      "source": [
        "# 2.2 LangChain structured agent creation with message patterns\n",
        "# Import LangChain chat models (with fallback to mock mode)\n",
        "try:\n",
        "    from langchain_anthropic import ChatAnthropic\n",
        "    anthropic_llm = ChatAnthropic(model=\"claude-3-5-haiku-latest\", temperature=0)\n",
        "except ImportError:\n",
        "    anthropic_llm = None\n",
        "\n",
        "# Create healthcare agent using prompt + examples + schema\n",
        "healthcare_agent = create_langchain_structured_agent(\n",
        "    name=\"HealthcareMessage\",\n",
        "    prompt_path=\"example_prompt.md\",\n",
        "    examples_path=\"example_examples.json\",\n",
        "    output_schema=ExampleAgentOutput,\n",
        "    llm=anthropic_llm  # Will use mock mode if None\n",
        ")\n",
        "\n",
        "# Test agent with user query - returns structured Pydantic object\n",
        "result1 = healthcare_agent(\"Find me an orthopedic surgeon\")\n",
        "print(f\"Healthcare agent result type: {type(result1)}\")\n",
        "print(f\"Response: {result1.response[:70]}...\")\n",
        "print(f\"Confidence: {result1.confidence}\")\n",
        "print(f\"Metadata: {list(result1.metadata.keys())}\")\n",
        "\n",
        "# Create reasoning agent with custom system message and different schema\n",
        "custom_system = \"You are an expert healthcare advisor. Provide detailed reasoning for insurance decisions.\"\n",
        "reasoning_agent = create_langchain_structured_agent(\n",
        "    name=\"ReasoningMessage\",\n",
        "    prompt_path=\"example_prompt.md\", \n",
        "    examples_path=\"example_examples.json\",\n",
        "    output_schema=ChainOfThoughtOutput,\n",
        "    system_message=custom_system,\n",
        "    llm=anthropic_llm\n",
        ")\n",
        "\n",
        "# Test reasoning agent - returns ChainOfThoughtOutput with structured reasoning\n",
        "result2 = reasoning_agent(\"What factors should I consider when choosing insurance?\")\n",
        "print(f\"\\nReasoning agent result type: {type(result2)}\")\n",
        "print(f\"Thinking: {result2.thinking[:60]}...\")\n",
        "print(f\"Conclusion: {result2.conclusion[:60]}...\")\n",
        "print(f\"Reasoning steps: {len(result2.steps)}\")\n",
        "print(f\"Confidence: {result2.confidence}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. üîç Dynamic Agent Discovery\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Using local database: postgresql://aq_home@[host]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-21 19:15:34,350 - langgraph_utils.AgentDiscovery - WARNING - Error loading agent workflow_prescription: Error loading module ...workflow_prescription: No module named '.'\n",
            "2025-06-21 19:15:34,353 - langgraph_utils.AgentDiscovery - WARNING - Error loading agent unit: Error loading module ...prompt_security.tests.unit.test_prompt_security_agent: No module named 'agents.prompt_security_agent'\n",
            "2025-06-21 19:15:34,355 - langgraph_utils.AgentDiscovery - WARNING - Error loading agent models: Error loading module ...prompt_security.models: No module named '.'\n",
            "2025-06-21 19:15:34,360 - langgraph_utils.AgentDiscovery - WARNING - Error loading agent models: Error loading module ...chat_communicator.models: No module named '.'\n",
            "2025-06-21 19:15:34,361 - langgraph_utils.AgentDiscovery - WARNING - Error loading agent regulatory: Error loading module ...regulatory.regulatory: No module named '.'\n",
            "2025-06-21 19:15:34,400 - langgraph_utils.AgentDiscovery - WARNING - Error loading agent tests: Error loading module ...regulatory.tests.test_regulatory_agent: cannot import name 'analyze_regulatory_strategy' from 'agents.regulatory.regulatory' (/Users/aq_home/1Projects/accessa/insurance_navigator/agents/regulatory/regulatory.py)\n",
            "2025-06-21 19:15:34,404 - langgraph_utils.AgentDiscovery - WARNING - Error loading agent tests: Error loading module ...task_requirements.tests.test_run_agent: cannot import name 'TaskRequirementsReactAgent' from 'agents.task_requirements.task_requirements' (/Users/aq_home/1Projects/accessa/insurance_navigator/agents/task_requirements/task_requirements.py)\n",
            "2025-06-21 19:15:34,408 - langgraph_utils.AgentDiscovery - INFO - Discovered 11 agents\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discovered 11 agents: ['agents', 'workflow_prescription', 'prompt_security', 'unit', 'models']...\n",
            "\n",
            "Agent 'agents':\n",
            "  Path: /Users/aq_home/1Projects/accessa/insurance_navigator/agents/__init__.py\n",
            "  Agent class: None\n",
            "  Factory function: None\n",
            "\n",
            "Agent 'workflow_prescription':\n",
            "  Path: /Users/aq_home/1Projects/accessa/insurance_navigator/agents/workflow_prescription/__init__.py\n",
            "  Agent class: None\n",
            "  Factory function: None\n",
            "  Error: Error loading module ...workflow_prescription: No module named '.'...\n",
            "\n",
            "Agent 'prompt_security':\n",
            "  Path: /Users/aq_home/1Projects/accessa/insurance_navigator/agents/prompt_security/prompt_security.py\n",
            "  Agent class: Found\n",
            "  Factory function: Found\n",
            "\n",
            "üîç Agent Discovery Report\n",
            "Base Path: /Users/aq_home/1Projects/accessa/insurance_navigator/agents\n",
            "Agents Found: 11\n",
            "==================================================\n",
            "\n",
            "üì¶ agents\n",
            "   Path: /Users/aq_home/1Projects/accessa/insurance_navigator/agents/__init__.py\n",
            "   Module: ..\n",
            "   Description: Agents package for the Insurance Navigator system.\n",
            "   ‚ö†Ô∏è  No instantiation method found\n",
            "\n",
            "üì¶ workflow_prescription\n",
            "   Path: /Users/aq_home/1Projects/accessa/insurance_navigator/agents/workflow_prescription/__init__.py\n",
            "   Module: ...workflow_prescription\n",
            "   ‚ùå Error: Error loading module ...workflow_prescription: No module named '.'\n",
            "\n",
            "üì¶ prompt_security\n",
            "   Path: /Users/aq_home/1Projects/accessa/insurance_navigator/agents/prompt_security/prompt_security.py\n",
            "   Module: ...prompt_security.prompt_security\n",
            "   Description: Prompt Security Agent Implementation\n",
            "   ‚úÖ Agent Class: PromptSecurityAgent\n",
            "   ‚úÖ Factory Function: get_config_manager\n",
            "\n",
            "üì¶ unit\n",
            "   Path: /Users/aq_home/1Projects/accessa/insurance_navigator/agents/prompt_security/tests/unit/test_prompt_security_agent.py\n",
            "   Module: ...prompt_security.tests.unit.test_prompt_security_agent\n",
            "   ‚ùå Error: Error loading module ...prompt_security.tests.unit.test_prompt_security_agent: No module named 'agents.prompt_security_agent'\n",
            "\n",
            "üì¶ models\n",
            "   Path: /Users/aq_home/1Projects/accessa/insurance_navigator/agents/chat_communicator/models/__init__.py\n",
            "   Module: ...chat_communicator.models\n",
            "   ‚ùå Error: Error loading module ...chat_communicator.models: No module named '.'\n",
            "\n",
            "üì¶ chat_communicator\n",
            "   Path: /Users/aq_home/1Projects/accessa/insurance_navigator/agents/chat_communicator/chat_communicator.py\n",
            "   Module: ...chat_communicator.chat_communicator\n",
            "   Description: Chat Communicator Agent\n",
            "   ‚úÖ Agent Class: ChatCommunicatorAgent\n",
            "   ‚úÖ Factory Function: get_conversation_service\n",
            "\n",
            "üì¶ regulatory\n",
            "   Path: /Users/aq_home/1Projects/accessa/insurance_navigator/agents/regulatory/regulatory.py\n",
            "   Module: ...regulatory.regulatory\n",
            "   ‚ùå Error: Error loading module ...regulatory.regulatory: No module named '.'\n",
            "\n",
            "üì¶ tests\n",
            "   Path: /Users/aq_home/1Projects/accessa/insurance_navigator/agents/task_requirements/tests/test_run_agent.py\n",
            "   Module: ...task_requirements.tests.test_run_agent\n",
            "   ‚ùå Error: Error loading module ...task_requirements.tests.test_run_agent: cannot import name 'TaskRequirementsReactAgent' from 'agents.task_requirements.task_requirements' (/Users/aq_home/1Projects/accessa/insurance_navigator/agents/task_requirements/task_requirements.py)\n",
            "\n",
            "üì¶ service_access_strategy\n",
            "   Path: /Users/aq_home/1Projects/accessa/insurance_navigator/agents/service_access_strategy/service_access_strategy.py\n",
            "   Module: ...service_access_strategy.service_access_strategy\n",
            "   Description: Service Access Strategy Agent\n",
            "   ‚úÖ Agent Class: ServiceAccessStrategyAgent\n",
            "\n",
            "üì¶ task_requirements\n",
            "   Path: /Users/aq_home/1Projects/accessa/insurance_navigator/agents/task_requirements/task_requirements.py\n",
            "   Module: ...task_requirements.task_requirements\n",
            "   Description: Task Requirements Agent with ReAct-based Processing\n",
            "   ‚úÖ Agent Class: TaskRequirementsAgent\n",
            "   ‚úÖ Factory Function: test_task_requirements_agent\n",
            "\n",
            "üì¶ patient_navigator\n",
            "   Path: /Users/aq_home/1Projects/accessa/insurance_navigator/agents/patient_navigator/patient_navigator.py\n",
            "   Module: ...patient_navigator.patient_navigator\n",
            "   Description: Patient Navigator Agent\n",
            "   ‚úÖ Agent Class: PatientNavigatorAgent\n"
          ]
        }
      ],
      "source": [
        "# 3.1 Dynamic agent discovery from project directory structure\n",
        "# Create discovery instance pointing to agents directory\n",
        "discovery = AgentDiscovery(base_path=str(project_root / \"agents\"))\n",
        "\n",
        "# Scan filesystem for agent modules and get structured metadata\n",
        "agents = discovery.discover_agents()\n",
        "agent_names = discovery.list_agents()\n",
        "print(f\"Discovered {len(agents)} agents: {agent_names[:5]}...\")\n",
        "\n",
        "# Extract detailed agent information (first 3 for demo)\n",
        "for name in agent_names[:3]:\n",
        "    info = discovery.get_agent_info(name)\n",
        "    print(f\"\\nAgent '{name}':\")\n",
        "    print(f\"  Path: {info.path}\")\n",
        "    print(f\"  Agent class: {'Found' if info.agent_class else 'None'}\")\n",
        "    print(f\"  Factory function: {'Found' if info.factory_function else 'None'}\")\n",
        "    if info.init_error:\n",
        "        print(f\"  Error: {info.init_error[:80]}...\")\n",
        "\n",
        "# Generate full discovery report with all agent metadata\n",
        "discovery.print_discovery_report()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failed to load 'agents': Error instantiating agent 'agents': No instantiation method found for agent 'age...\n",
            "Failed to load 'workflow_prescription': Agent 'workflow_prescription' has initialization error: Error loading module ......\n",
            "Failed to load 'prompt_security': Error instantiating agent 'prompt_security': get_config_manager() got an unexpec...\n",
            "\n",
            "Successfully loaded 0 agents\n"
          ]
        }
      ],
      "source": [
        "# 3.2 Agent loading with error handling and introspection\n",
        "# Attempt to load discovered agents with mock mode fallback\n",
        "loadable_agents = []\n",
        "for agent_name in agent_names[:3]:\n",
        "    try:\n",
        "        # Load agent instance with mock mode to avoid API dependencies\n",
        "        agent = discovery.load_agent(agent_name, use_mock=True)\n",
        "        loadable_agents.append((agent_name, agent))\n",
        "        print(f\"Loaded agent '{agent_name}': {type(agent).__name__}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load '{agent_name}': {str(e)[:80]}...\")\n",
        "\n",
        "print(f\"\\nSuccessfully loaded {len(loadable_agents)} agents\")\n",
        "\n",
        "# Introspect loaded agent methods and attributes\n",
        "if loadable_agents:\n",
        "    agent_name, agent = loadable_agents[0]\n",
        "    methods = [method for method in dir(agent) if not method.startswith('_')]\n",
        "    print(f\"{agent_name} available methods: {methods[:10]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. üß† Quick Agent Prototype\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-21 19:15:34,429 - langgraph_utils - INFO - Creating LangChain structured agent: LangChainHelper\n",
            "2025-06-21 19:15:34,431 - langgraph_utils - WARNING - No LLM provided, using mock mode for LangChainHelper\n",
            "2025-06-21 19:15:34,435 - langgraph_utils - INFO - Creating LangChain structured agent: ReasoningAgent\n",
            "2025-06-21 19:15:34,435 - langgraph_utils - WARNING - No LLM provided, using mock mode for ReasoningAgent\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "== LangChain Best Practice Integration ===\n",
            "\n",
            "üß™ Testing LangChain-Compliant Agent Function\n",
            "‚úÖ Created LangChain agent: LangChainHelper_langchain_agent\n",
            "\n",
            "üéØ LangChain Pattern Results:\n",
            "   Input: Find me a specialist who takes my insurance\n",
            "   Type returned: <class 'langgraph_utils.ExampleAgentOutput'>\n",
            "   Response: Mock response from LangChainHelper: I can help you with 'Find me a specialist wh...\n",
            "   Confidence: 0.8\n",
            "   Metadata keys: ['mock', 'agent', 'input_length', 'timestamp']\n",
            "   ‚úÖ Direct Pydantic object - no JSON parsing!\n",
            "\n",
            "üìä Comparison: Legacy vs LangChain Pattern\n",
            "\n",
            "1Ô∏è‚É£ Legacy Pattern (with fixed JSON generation):\n",
            "   Returns: Dict with validation wrapper\n",
            "   Validation: ‚úÖ Passed\n",
            "   Structured output: <class 'langgraph_utils.ExampleAgentOutput'>\n",
            "   Response: Mock response from LegacyHelper: I can help you with 'Find m...\n",
            "\n",
            "2Ô∏è‚É£ LangChain Pattern:\n",
            "   Returns: Direct Pydantic <class 'langgraph_utils.ExampleAgentOutput'>\n",
            "   Response: Mock response from LangChainHelper: I can help you with 'Fin...\n",
            "   ‚úÖ No validation wrapper needed!\n",
            "\n",
            "üîë Key Benefits of LangChain Pattern:\n",
            "‚úÖ Cleaner API - returns Pydantic objects directly\n",
            "‚úÖ Better error handling - schema binding at model level\n",
            "‚úÖ More reliable - uses tool calling instead of prompt requests\n",
            "‚úÖ Ecosystem integration - works seamlessly with LangChain\n",
            "‚úÖ Production ready - supports real LLMs with with_structured_output()\n",
            "\n",
            "üß† Testing with Chain-of-Thought Schema:\n",
            "   Type: <class 'langgraph_utils.ChainOfThoughtOutput'>\n",
            "   Thinking: Mock reasoning process: The user asked about 'How should I compare dif...\n",
            "   Conclusion: Mock conclusion based on the query about 'How should I compare differe...\n",
            "   Steps: 3 reasoning steps\n",
            "   Confidence: 0.8\n",
            "\n",
            "üí° Implementation Note:\n",
            "Both patterns work and are maintained for compatibility.\n",
            "Use create_langchain_structured_agent() for new development.\n",
            "Use quick_agent_prototype() for rapid prototyping with validation details.\n"
          ]
        }
      ],
      "source": [
        "# 4.1 FIXED: Demonstrate LangChain Best Practices in Our Implementation\n",
        "print(\"== LangChain Best Practice Integration ===\")\n",
        "\n",
        "# Test the NEW LangChain-compliant function\n",
        "print(\"\\nüß™ Testing LangChain-Compliant Agent Function\")\n",
        "langchain_agent = create_langchain_structured_agent(\n",
        "    name=\"LangChainHelper\",\n",
        "    prompt_path=\"example_prompt.md\",\n",
        "    examples_path=\"example_examples.json\",\n",
        "    output_schema=ExampleAgentOutput,\n",
        "    llm=None  # Mock mode for demo\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Created LangChain agent: {langchain_agent.__name__}\")\n",
        "\n",
        "# Test with direct Pydantic object return (LangChain pattern)\n",
        "test_query = \"Find me a specialist who takes my insurance\"\n",
        "result = langchain_agent(test_query)\n",
        "\n",
        "print(f\"\\nüéØ LangChain Pattern Results:\")\n",
        "print(f\"   Input: {test_query}\")\n",
        "print(f\"   Type returned: {type(result)}\")\n",
        "print(f\"   Response: {result.response[:80]}...\")\n",
        "print(f\"   Confidence: {result.confidence}\")\n",
        "print(f\"   Metadata keys: {list(result.metadata.keys())}\")\n",
        "print(f\"   ‚úÖ Direct Pydantic object - no JSON parsing!\")\n",
        "\n",
        "# Compare with our legacy approach\n",
        "print(f\"\\nüìä Comparison: Legacy vs LangChain Pattern\")\n",
        "\n",
        "# Legacy approach with validation wrapper\n",
        "print(f\"\\n1Ô∏è‚É£ Legacy Pattern (with fixed JSON generation):\")\n",
        "legacy_agent = quick_agent_prototype(\n",
        "    name=\"LegacyHelper\", \n",
        "    prompt_path=\"example_prompt.md\",\n",
        "    examples_path=\"example_examples.json\",\n",
        "    output_schema=ExampleAgentOutput,\n",
        "    llm=None\n",
        ")\n",
        "\n",
        "legacy_result = legacy_agent(test_query)\n",
        "print(f\"   Returns: Dict with validation wrapper\")\n",
        "print(f\"   Validation: {'‚úÖ Passed' if legacy_result['validation_passed'] else '‚ùå Failed'}\")\n",
        "if legacy_result['validation_passed']:\n",
        "    print(f\"   Structured output: {type(legacy_result['structured_output'])}\")\n",
        "    print(f\"   Response: {legacy_result['structured_output'].response[:60]}...\")\n",
        "\n",
        "print(f\"\\n2Ô∏è‚É£ LangChain Pattern:\")\n",
        "print(f\"   Returns: Direct Pydantic {type(result)}\")\n",
        "print(f\"   Response: {result.response[:60]}...\")\n",
        "print(f\"   ‚úÖ No validation wrapper needed!\")\n",
        "\n",
        "print(f\"\\nüîë Key Benefits of LangChain Pattern:\")\n",
        "print(\"‚úÖ Cleaner API - returns Pydantic objects directly\")\n",
        "print(\"‚úÖ Better error handling - schema binding at model level\")\n",
        "print(\"‚úÖ More reliable - uses tool calling instead of prompt requests\")\n",
        "print(\"‚úÖ Ecosystem integration - works seamlessly with LangChain\")\n",
        "print(\"‚úÖ Production ready - supports real LLMs with with_structured_output()\")\n",
        "\n",
        "# Demonstrate with Chain-of-Thought schema\n",
        "print(f\"\\nüß† Testing with Chain-of-Thought Schema:\")\n",
        "cot_agent = create_langchain_structured_agent(\n",
        "    name=\"ReasoningAgent\",\n",
        "    prompt_path=\"example_prompt.md\", \n",
        "    examples_path=\"example_examples.json\",\n",
        "    output_schema=ChainOfThoughtOutput,\n",
        "    llm=None\n",
        ")\n",
        "\n",
        "cot_result = cot_agent(\"How should I compare different insurance plans?\")\n",
        "print(f\"   Type: {type(cot_result)}\")\n",
        "print(f\"   Thinking: {cot_result.thinking[:70]}...\")\n",
        "print(f\"   Conclusion: {cot_result.conclusion[:70]}...\")\n",
        "print(f\"   Steps: {len(cot_result.steps)} reasoning steps\")\n",
        "print(f\"   Confidence: {cot_result.confidence}\")\n",
        "\n",
        "print(f\"\\nüí° Implementation Note:\")\n",
        "print(\"Both patterns work and are maintained for compatibility.\")\n",
        "print(\"Use create_langchain_structured_agent() for new development.\")\n",
        "print(\"Use quick_agent_prototype() for rapid prototyping with validation details.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4.1 üîß FIXED: Quick Agent Prototype (JSON Parsing Issue Resolved)\n",
        "\n",
        "**Problem Identified:** The original `quick_agent_prototype` function was generating plain text mock responses that failed JSON validation, causing the error:\n",
        "```\n",
        "Invalid JSON: Expecting value: line 1 column 2 (char 1)\n",
        "```\n",
        "\n",
        "**Root Cause:** Mock responses like `\"[Mock response for agent...\"` start with `[M` which JSON parser interprets as an invalid array.\n",
        "\n",
        "**Solution Implemented:** \n",
        "- Added `_generate_mock_data_for_schema()` function that creates valid JSON matching the Pydantic schema\n",
        "- Updated `quick_agent_prototype()` to generate structured JSON when a schema is provided\n",
        "- Maintained backward compatibility for unstructured outputs\n",
        "\n",
        "Let's demonstrate the fix:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== üîß FIXED Quick Agent Prototype Demo ===\n",
            "This demonstrates the fix for the JSON parsing error identified in the RCA.\n",
            "\n",
            "üß™ Test 1: HealthcareHelper with ExampleAgentOutput Schema\n",
            "‚úÖ Created agent: HealthcareHelper_agent\n",
            "   Documentation: Auto-generated agent function for 'HealthcareHelper' with structured output\n",
            "\n",
            "üî¨ Test 1: I need to find a dermatologist\n",
            "   Agent: HealthcareHelper\n",
            "   Validation: ‚úÖ PASSED\n",
            "   ‚úÖ Response: Mock response from HealthcareHelper: I can help you with 'I need to find a dermatologist...'. This i...\n",
            "   ‚úÖ Confidence: 0.8\n",
            "   ‚úÖ Metadata: {'mock': True, 'agent': 'HealthcareHelper', 'input_length': 30, 'timestamp': 'mock_timestamp'}\n",
            "   üìã Valid JSON Generated: {\n",
            "  \"response\": \"Mock response from HealthcareHelper: I can help you with 'I need to find a dermatologist...'. This is a simulated response for testing purposes.\",\n",
            "  \"confidence\": 0.8,\n",
            "  \"metadata\": {...\n",
            "\n",
            "üî¨ Test 2: Does my insurance cover MRI scans?\n",
            "   Agent: HealthcareHelper\n",
            "   Validation: ‚úÖ PASSED\n",
            "   ‚úÖ Response: Mock response from HealthcareHelper: I can help you with 'Does my insurance cover MRI scans?...'. Th...\n",
            "   ‚úÖ Confidence: 0.8\n",
            "   ‚úÖ Metadata: {'mock': True, 'agent': 'HealthcareHelper', 'input_length': 34, 'timestamp': 'mock_timestamp'}\n",
            "   üìã Valid JSON Generated: {\n",
            "  \"response\": \"Mock response from HealthcareHelper: I can help you with 'Does my insurance cover MRI scans?...'. This is a simulated response for testing purposes.\",\n",
            "  \"confidence\": 0.8,\n",
            "  \"metadata...\n",
            "\n",
            "üî¨ Test 3: I'm having severe headaches and need urgent care\n",
            "   Agent: HealthcareHelper\n",
            "   Validation: ‚úÖ PASSED\n",
            "   ‚úÖ Response: Mock response from HealthcareHelper: I can help you with 'I'm having severe headaches and need urgen...\n",
            "   ‚úÖ Confidence: 0.8\n",
            "   ‚úÖ Metadata: {'mock': True, 'agent': 'HealthcareHelper', 'input_length': 48, 'timestamp': 'mock_timestamp'}\n",
            "   üìã Valid JSON Generated: {\n",
            "  \"response\": \"Mock response from HealthcareHelper: I can help you with 'I'm having severe headaches and need urgent care...'. This is a simulated response for testing purposes.\",\n",
            "  \"confidence\": 0....\n",
            "\n",
            "üß† Test 2: ChainOfThought Schema Demonstration\n",
            "üî¨ Chain-of-Thought Test:\n",
            "   Validation: ‚úÖ PASSED\n",
            "   ü§î Thinking: Mock reasoning process: The user asked about 'How should I choose between di...'...\n",
            "   üí° Conclusion: Mock conclusion based on the query about 'How should I choose between di...'...\n",
            "   üìù Steps: 3 reasoning steps\n",
            "   üéØ Confidence: 0.8\n",
            "\n",
            "üÜö Test 3: Comparison - Agent WITHOUT Schema (Plain Text)\n",
            "üìÑ Plain Text Agent Result:\n",
            "   Output: [Mock response for agent 'PlainTextAgent' with input: I need help with insurance...]\n",
            "   Validation: N/A (no schema)\n",
            "\n",
            "‚úÖ Summary: JSON Parsing Issue RESOLVED!\n",
            "‚úÖ Mock responses now generate valid JSON when schema is provided\n",
            "‚úÖ Validation passes successfully for all structured outputs\n",
            "‚úÖ Multiple schemas supported (ExampleAgentOutput, ChainOfThoughtOutput)\n",
            "‚úÖ Backward compatibility maintained for unstructured outputs\n"
          ]
        }
      ],
      "source": [
        "# 4.2 FIXED Quick Agent Prototype Demo - Addresses JSON Parsing Issues\n",
        "print(\"=== üîß FIXED Quick Agent Prototype Demo ===\")\n",
        "print(\"This demonstrates the fix for the JSON parsing error identified in the RCA.\")\n",
        "\n",
        "# Test 1: Create agent with structured output (ExampleAgentOutput schema)\n",
        "print(\"\\nüß™ Test 1: HealthcareHelper with ExampleAgentOutput Schema\")\n",
        "fixed_prototype_agent = quick_agent_prototype(\n",
        "    name=\"HealthcareHelper\",\n",
        "    prompt_path=\"example_prompt.md\",\n",
        "    examples_path=\"example_examples.json\",\n",
        "    output_schema=ExampleAgentOutput,\n",
        "    pedantic_validation=False,\n",
        "    llm=None  # Mock mode now generates valid JSON!\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Created agent: {fixed_prototype_agent.__name__}\")\n",
        "print(f\"   Documentation: {fixed_prototype_agent.__doc__}\")\n",
        "\n",
        "# Test the fixed prototype\n",
        "test_inputs = [\n",
        "    \"I need to find a dermatologist\", \n",
        "    \"Does my insurance cover MRI scans?\",\n",
        "    \"I'm having severe headaches and need urgent care\"\n",
        "]\n",
        "\n",
        "for i, test_input in enumerate(test_inputs, 1):\n",
        "    print(f\"\\nüî¨ Test {i}: {test_input}\")\n",
        "    result = fixed_prototype_agent(test_input)\n",
        "    \n",
        "    print(f\"   Agent: {result['agent_name']}\")\n",
        "    print(f\"   Validation: {'‚úÖ PASSED' if result['validation_passed'] else '‚ùå FAILED'}\")\n",
        "    \n",
        "    if result.get('validation_error'):\n",
        "        print(f\"   ‚ùå Error: {result['validation_error']}\")\n",
        "    else:\n",
        "        # Show successful structured output\n",
        "        structured = result['structured_output']\n",
        "        print(f\"   ‚úÖ Response: {structured.response[:100]}...\")\n",
        "        print(f\"   ‚úÖ Confidence: {structured.confidence}\")\n",
        "        print(f\"   ‚úÖ Metadata: {structured.metadata}\")\n",
        "        \n",
        "        # Show the valid JSON that was generated\n",
        "        print(f\"   üìã Valid JSON Generated: {result['raw_output'][:200]}...\")\n",
        "\n",
        "print(f\"\\nüß† Test 2: ChainOfThought Schema Demonstration\")\n",
        "# Test with a different schema to show versatility\n",
        "thinking_agent = quick_agent_prototype(\n",
        "    name=\"ThinkingAgent\",\n",
        "    prompt_path=\"example_prompt.md\", \n",
        "    examples_path=\"example_examples.json\",\n",
        "    output_schema=ChainOfThoughtOutput,\n",
        "    pedantic_validation=False,\n",
        "    llm=None\n",
        ")\n",
        "\n",
        "thinking_result = thinking_agent(\"How should I choose between different health insurance plans?\")\n",
        "print(f\"üî¨ Chain-of-Thought Test:\")\n",
        "print(f\"   Validation: {'‚úÖ PASSED' if thinking_result['validation_passed'] else '‚ùå FAILED'}\")\n",
        "\n",
        "if thinking_result['validation_passed']:\n",
        "    cot = thinking_result['structured_output']\n",
        "    print(f\"   ü§î Thinking: {cot.thinking[:80]}...\")\n",
        "    print(f\"   üí° Conclusion: {cot.conclusion[:80]}...\")\n",
        "    print(f\"   üìù Steps: {len(cot.steps)} reasoning steps\")\n",
        "    print(f\"   üéØ Confidence: {cot.confidence}\")\n",
        "\n",
        "print(f\"\\nüÜö Test 3: Comparison - Agent WITHOUT Schema (Plain Text)\")\n",
        "# Show what happens without a schema (plain text mock)\n",
        "unstructured_agent = quick_agent_prototype(\n",
        "    name=\"PlainTextAgent\",\n",
        "    prompt_path=\"example_prompt.md\",\n",
        "    examples_path=\"example_examples.json\", \n",
        "    output_schema=None,  # No schema = plain text mock\n",
        "    llm=None\n",
        ")\n",
        "\n",
        "plain_result = unstructured_agent(\"I need help with insurance\")\n",
        "print(f\"üìÑ Plain Text Agent Result:\")\n",
        "print(f\"   Output: {plain_result['raw_output']}\")\n",
        "print(f\"   Validation: {'N/A (no schema)' if plain_result.get('structured_output') is None else 'Has validation'}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Summary: JSON Parsing Issue RESOLVED!\")\n",
        "print(\"‚úÖ Mock responses now generate valid JSON when schema is provided\")\n",
        "print(\"‚úÖ Validation passes successfully for all structured outputs\")\n",
        "print(\"‚úÖ Multiple schemas supported (ExampleAgentOutput, ChainOfThoughtOutput)\")\n",
        "print(\"‚úÖ Backward compatibility maintained for unstructured outputs\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Quick Agent Prototype Demo ===\n",
            "‚úÖ Created prototype agent: HealthcareHelper_agent\n",
            "\n",
            "=== Testing Prototype Agent ===\n",
            "\n",
            "üß™ Test 1: I need to find a dermatologist\n",
            "   Agent: HealthcareHelper\n",
            "   Output: {\n",
            "  \"response\": \"Mock response from HealthcareHelper: I can help you with 'I need to find a dermatol...\n",
            "   Validation: ‚úÖ Passed\n",
            "   Confidence: 0.8\n",
            "\n",
            "üß™ Test 2: Does my insurance cover MRI scans?\n",
            "   Agent: HealthcareHelper\n",
            "   Output: {\n",
            "  \"response\": \"Mock response from HealthcareHelper: I can help you with 'Does my insurance cover M...\n",
            "   Validation: ‚úÖ Passed\n",
            "   Confidence: 0.8\n",
            "\n",
            "üß™ Test 3: I'm having severe headaches and dizziness\n",
            "   Agent: HealthcareHelper\n",
            "   Output: {\n",
            "  \"response\": \"Mock response from HealthcareHelper: I can help you with 'I'm having severe headach...\n",
            "   Validation: ‚úÖ Passed\n",
            "   Confidence: 0.8\n"
          ]
        }
      ],
      "source": [
        "# 4.1 Create a quick prototype agent\n",
        "print(\"=== Quick Agent Prototype Demo ===\")\n",
        "\n",
        "# Create a prototype agent with structured output\n",
        "prototype_agent = quick_agent_prototype(\n",
        "    name=\"HealthcareHelper\",\n",
        "    prompt_path=\"example_prompt.md\",\n",
        "    examples_path=\"example_examples.json\",\n",
        "    output_schema=ExampleAgentOutput,\n",
        "    pedantic_validation=False,\n",
        "    llm=None  # Using mock mode (no actual LLM)\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Created prototype agent: {prototype_agent.__name__}\")\n",
        "\n",
        "# Test the prototype with different inputs\n",
        "test_inputs = [\n",
        "    \"I need to find a dermatologist\",\n",
        "    \"Does my insurance cover MRI scans?\", \n",
        "    \"I'm having severe headaches and dizziness\"\n",
        "]\n",
        "\n",
        "print(f\"\\n=== Testing Prototype Agent ===\")\n",
        "for i, test_input in enumerate(test_inputs):\n",
        "    print(f\"\\nüß™ Test {i+1}: {test_input}\")\n",
        "    result = prototype_agent(test_input)\n",
        "    \n",
        "    print(f\"   Agent: {result['agent_name']}\")\n",
        "    print(f\"   Output: {result['raw_output'][:100]}...\")\n",
        "    print(f\"   Validation: {'‚úÖ Passed' if result['validation_passed'] else '‚ùå Failed'}\")\n",
        "    \n",
        "    if result.get('validation_error'):\n",
        "        print(f\"   Error: {result['validation_error'][:100]}...\")\n",
        "    \n",
        "    if result.get('structured_output'):\n",
        "        print(f\"   Confidence: {result['structured_output'].confidence}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. üï∏Ô∏è LangGraph Workflow Construction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LangGraph functions defined with proper state schema\n"
          ]
        }
      ],
      "source": [
        "# 5.1 Proper LangGraph workflow construction following official patterns\n",
        "# Import LangGraph components and define state schema\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_core.messages import BaseMessage\n",
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"Proper LangGraph state schema following official documentation\"\"\"\n",
        "    messages: Annotated[list[BaseMessage], add_messages]\n",
        "    user_input: str\n",
        "    analysis: str\n",
        "    urgency_level: str\n",
        "    keywords: list\n",
        "    processing_result: str\n",
        "    final_response: str\n",
        "\n",
        "# Define node functions that work with dictionary state (LangGraph standard)\n",
        "def analyze_input(state: GraphState) -> GraphState:\n",
        "    \"\"\"Analyze user input and extract key information\"\"\"\n",
        "    user_input = state.get(\"user_input\", \"\")\n",
        "    analysis = f\"Analyzed: {user_input[:50]}...\"\n",
        "    \n",
        "    return {\n",
        "        \"analysis\": analysis,\n",
        "        \"messages\": [{\"role\": \"assistant\", \"content\": f\"Analysis complete for: {user_input[:30]}...\"}]\n",
        "    }\n",
        "\n",
        "def process_request(state: GraphState) -> GraphState:\n",
        "    \"\"\"Process the analyzed request\"\"\"\n",
        "    analysis = state.get(\"analysis\", \"No analysis\")\n",
        "    processing_result = f\"Processed based on: {analysis}\"\n",
        "    \n",
        "    return {\n",
        "        \"processing_result\": processing_result,\n",
        "        \"messages\": [{\"role\": \"assistant\", \"content\": \"Request processed successfully\"}]\n",
        "    }\n",
        "\n",
        "def format_response(state: GraphState) -> GraphState:\n",
        "    \"\"\"Format the final response for output\"\"\"\n",
        "    processing_result = state.get(\"processing_result\", \"No result\")\n",
        "    final_response = f\"Final response: {processing_result}\"\n",
        "    \n",
        "    return {\n",
        "        \"final_response\": final_response,\n",
        "        \"messages\": [{\"role\": \"assistant\", \"content\": final_response}]\n",
        "    }\n",
        "\n",
        "# Conditional routing function for LangGraph\n",
        "def should_process(state: GraphState) -> str:\n",
        "    \"\"\"Determine workflow routing based on analysis results\"\"\"\n",
        "    return \"process\" if state.get(\"analysis\") else \"end\"\n",
        "\n",
        "print(\"LangGraph functions defined with proper state schema\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Workflow compiled successfully\n",
            "Workflow completed\n",
            "Messages: 3\n",
            "Analysis: Analyzed: I need help finding a cardiologist...\n",
            "Final response: Final response: Processed based on: Analyzed: I need help finding a cardiologist......\n"
          ]
        }
      ],
      "source": [
        "# 5.2 Build and test healthcare workflow using proper LangGraph patterns\n",
        "# Create LangGraph StateGraph with proper state schema\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "# Add nodes to the graph using official LangGraph pattern\n",
        "workflow.add_node(\"analyze\", analyze_input)\n",
        "workflow.add_node(\"process\", process_request) \n",
        "workflow.add_node(\"format\", format_response)\n",
        "\n",
        "# Define workflow routing with conditional edges\n",
        "workflow.set_entry_point(\"analyze\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"analyze\",\n",
        "    should_process,\n",
        "    {\"process\": \"process\", \"end\": \"format\"}\n",
        ")\n",
        "workflow.add_edge(\"process\", \"format\")\n",
        "\n",
        "# Compile the workflow (LangGraph requirement)\n",
        "compiled_workflow = workflow.compile()\n",
        "print(\"Workflow compiled successfully\")\n",
        "\n",
        "# Test workflow execution with proper state dictionary\n",
        "initial_state = {\n",
        "    \"user_input\": \"I need help finding a cardiologist\",\n",
        "    \"messages\": [],\n",
        "    \"analysis\": \"\",\n",
        "    \"urgency_level\": \"\",\n",
        "    \"keywords\": [],\n",
        "    \"processing_result\": \"\",\n",
        "    \"final_response\": \"\"\n",
        "}\n",
        "\n",
        "try:\n",
        "    # Execute workflow and capture results (proper LangGraph invoke)\n",
        "    result = compiled_workflow.invoke(initial_state)\n",
        "    print(f\"Workflow completed\")\n",
        "    print(f\"Messages: {len(result.get('messages', []))}\")\n",
        "    print(f\"Analysis: {result.get('analysis', 'None')}\")\n",
        "    print(f\"Final response: {result.get('final_response', 'No response')[:100]}...\")\n",
        "except Exception as e:\n",
        "    print(f\"Workflow execution failed: {str(e)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. üîÅ Workflow Chaining\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enhanced workflow with parallel nodes compiled\n",
            "Parallel workflow completed\n",
            "Analysis: Analyzed: I need urgent help finding a cardiologist for ches...\n",
            "Urgency: high\n",
            "Keywords: ['urgent', 'finding', 'cardiologist', 'chest']\n",
            "Final response: Final response: Processed based on: Analyzed: I need urgent help finding a cardiologist for ches......\n"
          ]
        }
      ],
      "source": [
        "# 6.1 Parallel node execution and workflow chaining with proper LangGraph patterns\n",
        "# Define parallel processing nodes for simultaneous execution\n",
        "def analyze_urgency(state: GraphState) -> GraphState:\n",
        "    \"\"\"Analyze urgency level in parallel with main processing\"\"\"\n",
        "    user_input = state.get(\"user_input\", \"\")\n",
        "    urgency = \"high\" if any(word in user_input.lower() for word in [\"urgent\", \"emergency\", \"pain\"]) else \"normal\"\n",
        "    \n",
        "    return {\n",
        "        \"urgency_level\": urgency,\n",
        "        \"messages\": [{\"role\": \"assistant\", \"content\": f\"Urgency assessed: {urgency}\"}]\n",
        "    }\n",
        "\n",
        "def extract_keywords(state: GraphState) -> GraphState:\n",
        "    \"\"\"Extract keywords in parallel with main processing\"\"\"\n",
        "    user_input = state.get(\"user_input\", \"\")\n",
        "    keywords = [word for word in user_input.lower().split() if len(word) > 4]\n",
        "    \n",
        "    return {\n",
        "        \"keywords\": keywords,\n",
        "        \"messages\": [{\"role\": \"assistant\", \"content\": f\"Keywords extracted: {', '.join(keywords[:3])}\"}]\n",
        "    }\n",
        "\n",
        "# Create enhanced workflow with parallel nodes\n",
        "enhanced_workflow = StateGraph(GraphState)\n",
        "\n",
        "# Add parallel processing nodes that can run simultaneously\n",
        "enhanced_workflow.add_node(\"analyze_input\", analyze_input)\n",
        "enhanced_workflow.add_node(\"analyze_urgency\", analyze_urgency)  # Parallel node\n",
        "enhanced_workflow.add_node(\"extract_keywords\", extract_keywords)  # Parallel node\n",
        "enhanced_workflow.add_node(\"process_request\", process_request)\n",
        "enhanced_workflow.add_node(\"format_response\", format_response)\n",
        "\n",
        "# Set up parallel execution pattern from LangGraph documentation\n",
        "enhanced_workflow.set_entry_point(\"analyze_input\")\n",
        "\n",
        "# From analyze_input, branch to two parallel nodes\n",
        "enhanced_workflow.add_edge(\"analyze_input\", \"analyze_urgency\")\n",
        "enhanced_workflow.add_edge(\"analyze_input\", \"extract_keywords\")\n",
        "\n",
        "# Both parallel nodes feed into process_request\n",
        "enhanced_workflow.add_edge(\"analyze_urgency\", \"process_request\")\n",
        "enhanced_workflow.add_edge(\"extract_keywords\", \"process_request\")\n",
        "\n",
        "# Final processing\n",
        "enhanced_workflow.add_edge(\"process_request\", \"format_response\")\n",
        "\n",
        "# Compile the enhanced workflow\n",
        "compiled_enhanced = enhanced_workflow.compile()\n",
        "print(\"Enhanced workflow with parallel nodes compiled\")\n",
        "\n",
        "# Test parallel execution\n",
        "parallel_state = {\n",
        "    \"user_input\": \"I need urgent help finding a cardiologist for chest pain\",\n",
        "    \"messages\": [],\n",
        "    \"analysis\": \"\",\n",
        "    \"urgency_level\": \"\",\n",
        "    \"keywords\": [],\n",
        "    \"processing_result\": \"\",\n",
        "    \"final_response\": \"\"\n",
        "}\n",
        "\n",
        "try:\n",
        "    # Execute workflow with parallel node processing\n",
        "    parallel_result = compiled_enhanced.invoke(parallel_state)\n",
        "    print(f\"Parallel workflow completed\")\n",
        "    print(f\"Analysis: {parallel_result.get('analysis', 'None')}\")\n",
        "    print(f\"Urgency: {parallel_result.get('urgency_level', 'None')}\")\n",
        "    print(f\"Keywords: {parallel_result.get('keywords', [])}\")\n",
        "    print(f\"Final response: {parallel_result.get('final_response', 'No response')[:100]}...\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Parallel workflow failed: {str(e)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 7. üìã Summary\n",
        "\n",
        "### Core LangGraph Components Demonstrated\n",
        "\n",
        "1. **üìÑ Prompt Composition**: Template merging, example conversion, placeholder substitution\n",
        "2. **üß± Structured Validation**: Pydantic schema validation, error handling, LangChain integration\n",
        "3. **üîç Dynamic Agent Discovery**: Filesystem scanning, module introspection, agent loading\n",
        "4. **üß† Quick Prototyping**: Combined prompt+validation, structured output generation\n",
        "5. **üï∏Ô∏è LangGraph Workflows**: StateGraph construction, node/edge definition, proper state management\n",
        "6. **‚ö° Parallel Execution**: Simultaneous node processing, following LangGraph parallelization patterns\n",
        "\n",
        "### Key Data Flow Patterns\n",
        "\n",
        "- **Files ‚Üí Templates ‚Üí Structured Output**: `prompt.md` + `examples.json` ‚Üí `PromptTemplate` ‚Üí `Pydantic Object`\n",
        "- **Agent Discovery ‚Üí Loading**: `filesystem scan` ‚Üí `AgentInfo` ‚Üí `loaded agent instance`\n",
        "- **LangGraph Execution**: `GraphState dict` ‚Üí `node functions` ‚Üí `updated state dict`\n",
        "- **Parallel Processing**: `initial_state` ‚Üí `[node_1, node_2]` ‚Üí `merged_state` ‚Üí `next_node`\n",
        "\n",
        "### Core LangGraph Usage Patterns\n",
        "\n",
        "- `StateGraph(GraphState)` - Official LangGraph state management with TypedDict schema\n",
        "- `workflow.add_node(name, function)` - Node registration with dictionary state functions\n",
        "- `workflow.add_conditional_edges()` - Conditional routing based on state values\n",
        "- `workflow.compile().invoke(state_dict)` - Proper workflow compilation and execution\n",
        "- **Parallel Nodes**: Multiple nodes receiving same input, outputs merged automatically\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 7. üìã Summary\n",
        "\n",
        "This notebook demonstrated comprehensive LangGraph workflow patterns and utilities:\n",
        "\n",
        "### ‚úÖ What We Accomplished\n",
        "\n",
        "1. **üìÑ Prompt Composition**: \n",
        "   - Loaded prompts from files with placeholder merging\n",
        "   - Converted JSON examples to Markdown format automatically\n",
        "   - Merged templates with user input and examples\n",
        "\n",
        "2. **üß± Structured Validation**:\n",
        "   - Created validators for Pydantic schemas\n",
        "   - Demonstrated lenient vs pedantic validation modes\n",
        "   - Showed helpful error formatting\n",
        "\n",
        "3. **üîç Dynamic Agent Discovery**:\n",
        "   - Automatically discovered agents in the project directory\n",
        "   - Loaded agent information without hardcoded paths\n",
        "   - Attempted agent instantiation with error handling\n",
        "\n",
        "4. **üß† Quick Agent Prototyping**:\n",
        "   - Combined prompt merging with structured validation\n",
        "   - Created prototype agents with minimal code\n",
        "   - Tested with multiple inputs\n",
        "\n",
        "5. **üï∏Ô∏è LangGraph Workflow Construction**:\n",
        "   - Built workflows using proper StateGraph patterns\n",
        "   - Added nodes, edges, and conditional routing\n",
        "   - Demonstrated proper state management with TypedDict\n",
        "\n",
        "6. **‚ö° Parallel Node Execution**:\n",
        "   - Created workflows with simultaneous node processing\n",
        "   - Implemented LangGraph parallelization patterns\n",
        "   - Showed automatic state merging from parallel branches\n",
        "\n",
        "### üöÄ Next Steps\n",
        "\n",
        "- Integrate with your existing agents using the discovery system\n",
        "- Create custom GraphState schemas for your specific use cases\n",
        "- Build complex multi-agent workflows with parallel processing\n",
        "- Add callback handlers for token usage tracking (see [LangChain discussion](https://github.com/langchain-ai/langchain/discussions/24683))\n",
        "\n",
        "### üìñ Usage Tips\n",
        "\n",
        "- Use proper TypedDict state schemas for LangGraph workflows\n",
        "- Follow official LangGraph patterns for state management\n",
        "- Create pedantic validators for production systems\n",
        "- Use the discovery system to avoid hardcoded agent imports\n",
        "- Implement parallel nodes for performance optimization\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

# CONTEXT.md ‚Äî Short-Term Chat Memory MVP

## üß† Purpose
Implement a chat-specific short-term memory mechanism to support continuity across user-agent interactions within a single goal-oriented chat thread. This enables agents to access a unified summary of prior decisions, clarifications, and general context, without relying on full transcripts.

## ‚úÖ In-Scope
- One **canonical summary** per chat, stored in Supabase `chat_metadata`.
- Fields: 
  - `user_confirmed`: facts explicitly confirmed by the user.
  - `llm_inferred`: model-derived assumptions not directly confirmed.
  - `general_summary`: overarching summary of the chat goal and progress.
- Passive memory update triggered **after input-processing workflow completes**, before supervisor handoff.
- Summary generated by **dedicated MCP summarizer agent**, using Claude Haiku.
- Summary and write process split into two sequential steps:
  1. MCP summarizes using prior context + new user/agent exchange.
  2. Sequential workflow step uploads result to `chat_metadata`.

## ‚ùå Out of Scope
- Multi-chat or cross-thread memory access
- Agent-specific memory views
- Key-value fact memory (e.g., `user_zip = 94110`)
- Active memory shaping or "what should I remember" interactions
- Intent graphs, historical memory rehydration

## üì¶ Storage
- Memory stored in `chat_metadata` table per chat.
- Backed by Supabase (PostgreSQL).
- Summary capped at an arbitrary max size (TBD). If exceeded, system instructs user to start a new chat.
- Update status tracked in `chat_context_queue` table with fields:
  - `chat_id`
  - `new_context_snippet`
  - `status`: `pending_summarization`, `ready_to_write`, `complete`

## üß© Integration Points
- **Input Processing Workflow**: triggers the memory update after completion.
- **MCP Summarizer Agent**: invoked by sequential workflow step, follows base agent pattern.
- **Sequential Workflow Step**: reads from `chat_context_queue`, invokes MCP summarization, uploads summary to `chat_metadata`.
- **Existing MCP Implementation**: serves as reference for orchestration and permission control.

## ‚ö†Ô∏è Edge Cases
| Case | Handling |
|------|----------|
| Summary too long | Prompt user to start a new chat if context exceeds threshold |
| Partial write failure | Use `chat_context_queue` as write-ahead log; retry on next tick |
| Stale context | Agents may use stale summary if update is in-flight; acceptable in MVP |
| LLM crash or timeout | Queue entry remains in `pending_summarization` and can be retried |

## üß™ Open Questions
- What is the ideal **token threshold** for triggering a new chat?
- Should `chat_context_queue` store **prior summary reference** for delta-based summarization?
- Do we ever need to support **agent-triggered updates** in addition to passive ones?

---

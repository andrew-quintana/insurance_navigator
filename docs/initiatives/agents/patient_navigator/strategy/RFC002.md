# RFC002: Strategy Evaluation & Validation System - MVP Technical Architecture

## Document Context

This RFC002 defines the technical architecture for the Strategy Evaluation & Validation System MVP, building upon requirements from PRD002.md and incorporating simplifications from REFACTOR001.md. The system employs an LLM-first approach with prompt engineering over complex algorithms.

**Reference Documents:**
- PRD002.md - MVP requirements with speed/cost/effort optimization
- REFACTOR001.md - Simplification prescription from complex 001 implementation
- Existing BaseAgent patterns and Supabase integration architecture

## Overview

The Strategy Evaluation & Validation System MVP is a healthcare access strategy generator that leverages LLM-driven logic to produce 4 optimization-focused strategies in under 30 seconds. The system prioritizes prompt engineering, semantic search, and simplified toolchains over complex analytical approaches.

### Key Architecture Principles

1. **LLM-First Design**: Context engineering + prompt engineering over algorithmic complexity
2. **MVP Simplification**: 4-component workflow with high-level interactions
3. **Simplified Toolchain**: Tavily + OpenAI + Supabase + Python
4. **Speed/Cost/Effort Optimization**: Replacing quality metrics with effort measurement
5. **Buffer-Based Storage**: Agent-orchestrated flow with buffer → commit pattern

## Technical Architecture

### System Components

```
┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐    ┌────────────────────┐
│   StrategyMCP   │───►│ StrategyCreator  │───►│ RegulatoryAgent │───►│ StrategyMemoryLite │
│   (Context)     │    │   (Generation)   │    │  (Validation)   │    │   (Workflow)       │
└─────────────────┘    └──────────────────┘    └─────────────────┘    └────────────────────┘
```

#### 1. StrategyMCP Tool (Context Gathering)
- **Purpose**: Simplified context coordinator using Tavily-only web search
- **Architecture**: MCP tool pattern following `agents/tooling/mcp/` structure
- **Key Functions**:
  - Plan constraint processing
  - Tavily web search integration (3 queries per optimization type)
  - Semantic similarity search of existing strategies via pgvector
  - Regulatory context retrieval from documents schema

#### 2. StrategyCreator Agent (Strategy Generation)
- **Purpose**: High-level strategy generation via prompt engineering
- **Architecture**: BaseAgent inheritance following `agents/patient_navigator/` patterns
- **Key Functions**:
  - 4-strategy generation: speed, cost, effort, balanced
  - LLM-driven optimization through specialized prompts
  - Self-scoring mechanism (0.0-1.0 for speed/cost/effort)
  - Template-based output formatting

#### 3. RegulatoryAgent (Compliance Validation)
- **Purpose**: Simplified LLM-based compliance checking
- **Architecture**: BaseAgent inheritance with prompt-based validation
- **Key Functions**:
  - Single LLM call for compliance assessment
  - Regulatory context integration from documents schema
  - Validation result categorization (approved/flagged/rejected)
  - Confidence scoring and audit trail generation

#### 4. StrategyMemoryLiteWorkflow (Buffer-Based Storage)
- **Purpose**: MVP buffer-based storage workflow with dual scoring system
- **Architecture**: Python workflow with direct Supabase SDK integration
- **Key Functions**:
  - Buffer-based storage: strategies_buffer → strategies → strategy_vector_buffer → strategy_vectors
  - Dual scoring: LLM scores (creation) + human scores (feedback)
  - Constraint-based retrieval with vector similarity
  - Idempotent processing with content hash deduplication

### Agent-Orchestrated Flow

The system implements a buffer-based workflow pattern:

1. **Strategy Generator** produces 4 strategy variants (speed, cost, effort, balanced)
2. **Regulatory Agent** evaluates each strategy for feasibility
3. **Validated strategies** are emitted as markdown with metadata (scores, variant type)
4. **Strategy ingestion service** logs markdown into `strategies_buffer`
5. **Valid entries** are committed to `strategies` table
6. **Markdown content** is passed to embedding pipeline
7. **Embeddings** are stored via `strategy_vector_buffer` → `strategy_vectors`

Each step:
- Is idempotent
- Emits structured logs (strategy_id, variant, score, markdown hash)
- Embedding and write operations follow buffer → commit pattern
- Validation ensures only cleared strategies are saved and embedded

### Database Architecture - MVP 4-Table Design

```sql
-- Core strategy metadata with embedded scoring
CREATE TABLE strategies.strategies (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  title TEXT NOT NULL,
  category TEXT NOT NULL,
  approach TEXT NOT NULL,
  rationale TEXT NOT NULL,
  actionable_steps JSONB NOT NULL,
  
  -- Plan constraint context
  plan_constraints JSONB NOT NULL,
  
  -- LLM scoring (0.0-1.0, set on creation)
  llm_score_speed NUMERIC(3,2) CHECK (llm_score_speed >= 0.0 AND llm_score_speed <= 1.0),
  llm_score_cost NUMERIC(3,2) CHECK (llm_score_cost >= 0.0 AND llm_score_cost <= 1.0),
  llm_score_effort NUMERIC(3,2) CHECK (llm_score_effort >= 0.0 AND llm_score_effort <= 1.0),
  
  -- Human effectiveness scoring (1.0-5.0, updated via feedback)
  human_score_effectiveness NUMERIC(3,2) CHECK (human_score_effectiveness >= 1.0 AND human_score_effectiveness <= 5.0),
  num_ratings INTEGER DEFAULT 0,
  
  -- Reliability and validation fields
  content_hash TEXT UNIQUE, -- For deduplication
  validation_status TEXT DEFAULT 'pending' CHECK (validation_status IN ('pending', 'approved', 'flagged', 'rejected')),
  
  -- Audit fields
  author_id UUID REFERENCES auth.users(id),
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

-- Vector embeddings for semantic search
CREATE TABLE strategies.strategy_vectors (
  strategy_id UUID PRIMARY KEY REFERENCES strategies.strategies(id) ON DELETE CASCADE,
  embedding VECTOR(1536), -- OpenAI text-embedding-3-small
  model_version TEXT NOT NULL DEFAULT 'text-embedding-3-small',
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

-- Processing buffer for reliability
CREATE TABLE strategies.strategies_buffer (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  strategy_data JSONB NOT NULL,
  content_hash TEXT NOT NULL,
  status TEXT DEFAULT 'pending' CHECK (status IN ('pending', 'processing', 'completed', 'failed', 'abandoned')),
  retry_count INTEGER DEFAULT 0,
  expires_at TIMESTAMPTZ DEFAULT (NOW() + INTERVAL '24 hours'),
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

-- Vector processing buffer
CREATE TABLE strategies.strategy_vector_buffer (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  strategy_id UUID REFERENCES strategies.strategies(id),
  content_hash TEXT NOT NULL,
  embedding VECTOR(1536),
  model_version TEXT NOT NULL DEFAULT 'text-embedding-3-small',
  status TEXT DEFAULT 'pending' CHECK (status IN ('pending', 'processing', 'completed', 'failed', 'abandoned')),
  retry_count INTEGER DEFAULT 0,
  expires_at TIMESTAMPTZ DEFAULT (NOW() + INTERVAL '24 hours'),
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

-- Performance indexes
CREATE INDEX idx_strategies_constraints ON strategies.strategies USING gin(plan_constraints);
CREATE INDEX idx_strategies_llm_scores ON strategies.strategies (llm_score_speed, llm_score_cost, llm_score_effort);
CREATE INDEX idx_strategies_validation ON strategies.strategies (validation_status, created_at);
CREATE INDEX idx_strategy_vectors_embedding ON strategies.strategy_vectors USING ivfflat (embedding vector_cosine_ops);
CREATE INDEX idx_strategies_buffer_status ON strategies.strategies_buffer (status, expires_at);
CREATE INDEX idx_strategy_vector_buffer_status ON strategies.strategy_vector_buffer (status, expires_at);
```

### Python Workflow Orchestration

```python
class StrategyMemoryLiteWorkflow:
    """
    StrategyMemoryLite Workflow - Buffer-based strategy storage and retrieval
    
    Implements agent-orchestrated flow with buffer → commit pattern:
    1. Strategy Generator produces 4 strategy variants
    2. Regulatory Agent evaluates each strategy for feasibility
    3. Validated strategies are emitted as markdown with metadata
    4. Strategy ingestion service logs markdown into strategies_buffer
    5. Valid entries are committed to strategies table
    6. Markdown content is passed to embedding pipeline
    7. Embeddings are stored via strategy_vector_buffer → strategy_vectors
    """
    
    def __init__(self):
        self.supabase = create_client(SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY)
        self.logger = logging.getLogger(__name__)

    async def store_strategies(self, strategies: List[Strategy]) -> List[StorageResult]:
        """Store strategies using buffer-based workflow"""
        # Implementation follows buffer → commit pattern
        pass

    async def retrieve_strategies(self, plan_constraints: PlanConstraints, limit: int = 10) -> List[Strategy]:
        """Retrieve strategies using constraint-based filtering and vector similarity"""
        # Implementation with constraint pre-filtering and vector similarity
        pass
```

## Technical Decisions

### 1. Python-First Architecture vs. TypeScript Approach

**Decision**: Implement all components in Python for consistency and maintainability

**Rationale**:
- **Language Consistency**: Matches existing backend patterns and BaseAgent inheritance
- **Development Speed**: Faster implementation with existing Python infrastructure
- **Maintainability**: Simpler dependency management and testing
- **Integration**: Easier integration with existing Supabase SDK and BaseAgent patterns

**Alternatives Considered**:
- TypeScript implementation (rejected: language inconsistency with existing patterns)
- Hybrid Python/TypeScript approach (rejected: increased complexity)

### 2. Buffer-Based Storage Workflow vs. Direct Storage

**Decision**: Implement buffer-based storage workflow for reliability and idempotency

**Rationale**:
- **Reliability**: Buffer provides safety net for processing failures
- **Idempotency**: Content hash prevents duplicate processing
- **Scalability**: Buffer can handle processing backlogs
- **Audit Trail**: Complete processing history for debugging

**Implementation Pattern**:
```
strategies_buffer → strategies → strategy_vector_buffer → strategy_vectors
```

### 3. Tavily-Only Web Search vs. Multi-Provider Fallback

**Decision**: Single Tavily integration with graceful degradation

**Rationale**:
- **Simplicity**: Reduced integration complexity and failure modes
- **Cost Efficiency**: Single API contract and billing relationship
- **Performance**: Consistent 5-second timeout without cascading delays
- **Reliability**: Fallback to semantic search when web search fails

**Alternatives Considered**:
- Google → Bing → DuckDuckGo cascade (rejected: complex error handling)
- Parallel multi-provider search (rejected: cost and complexity)

### 4. MVP 4-Table Design vs. Complex Multi-Table Schema

**Decision**: Simplified 4-table approach with buffer-based processing

**Rationale**:
- **Performance**: Buffer isolation prevents processing bottlenecks
- **Maintainability**: Clear separation of concerns
- **Scalability**: Follows existing pgvector patterns from documents schema
- **Development Speed**: Reduced migration complexity

**Alternatives Considered**:
- Single table with embedded vectors (rejected: query performance issues)
- Complex multi-table normalized design (rejected: over-engineering for MVP)

### 5. Speed/Cost/Effort vs. Speed/Cost/Quality Optimization

**Decision**: Replace quality metrics with effort measurement

**Rationale**:
- **User Value**: Effort measurement more actionable for healthcare consumers
- **Measurability**: Effort easier to quantify than subjective quality
- **Differentiation**: Creates distinct optimization strategies
- **Practical Focus**: Aligns with real-world healthcare decision factors

**Database Migration**:
```sql
ALTER TABLE strategies.strategies 
  RENAME COLUMN llm_score_quality TO llm_score_effort;
```

## Implementation Plan

### Phase 1: Core Infrastructure (Week 1)
1. **Database Schema Setup**
   - Create MVP 4-table schema with speed/cost/effort scoring
   - Set up pgvector indexes and similarity functions
   - Configure RLS policies following existing patterns

2. **Python Workflow Foundation**
   - Implement buffer-based workflow orchestration
   - Set up state management between components
   - Add error handling and timeout mechanisms

### Phase 2: Component Implementation (Week 2-3)
1. **StrategyMCP Tool**
   - Tavily API integration with 3-query generation
   - Semantic search via pgvector similarity
   - Regulatory context retrieval from documents schema

2. **StrategyCreator Agent**
   - 4-strategy prompt engineering (speed/cost/effort/balanced)
   - LLM self-scoring mechanism
   - Template-based output formatting

3. **RegulatoryAgent**
   - Single LLM compliance validation
   - Confidence scoring and categorization
   - Integration with existing documents schema

4. **StrategyMemoryLiteWorkflow**
   - Buffer-based storage workflow implementation
   - Dual scoring system implementation
   - Vector embedding generation and storage

### Phase 3: Integration & Testing (Week 4)
1. **End-to-End Workflow Testing**
   - Complete buffer-based workflow execution validation
   - Performance benchmarking (<30 second requirement)
   - Error handling and graceful degradation testing

2. **Component Testing**
   - Individual tool and agent testing
   - Mock external service integration
   - Database operation validation

## Risk Assessment & Mitigation

### Technical Risks

**R001: LLM Response Quality Variability**
- *Risk*: Inconsistent strategy quality across different constraint sets
- *Mitigation*: Comprehensive prompt engineering with examples and constraints
- *Monitoring*: Track human effectiveness scores and feedback patterns

**R002: Tavily API Reliability**
- *Risk*: Single point of failure for web search functionality
- *Mitigation*: Graceful degradation to semantic search when Tavily fails
- *Fallback*: 5-second timeout with cached results when available

**R003: Vector Search Performance**
- *Risk*: pgvector queries may degrade with scale
- *Mitigation*: Proper indexing and constraint-based pre-filtering
- *Optimization*: Regular VACUUM and index maintenance

### Integration Risks

**R004: BaseAgent Pattern Compatibility**
- *Risk*: New agents may not integrate properly with existing patterns
- *Mitigation*: Follow established inheritance patterns and interfaces
- *Validation*: Component testing against existing BaseAgent contracts

**R005: Supabase SDK Performance**
- *Risk*: Direct SDK calls may not scale under load
- *Mitigation*: Connection pooling and query optimization
- *Monitoring*: Database connection and query performance metrics

### Data Quality & Processing Risks

**R006: Strategy Generation Quality**
- *Risk*: Generator produces malformed or low-quality markdown
- *Effect*: Junk strategies pollute retrieval and embedding quality
- *Mitigation*: LLM-based quality evaluation step in regulatory agent workflow
- *Implementation*: Regulatory agent ReAct pattern includes quality assessment before approval

**R007: Database Write Failures**
- *Risk*: Write to strategies table or buffer fails, causing strategy loss
- *Effect*: Missing variant sets and incomplete strategy coverage
- *Mitigation*: Wrap storage operations in transactions with retry logic
- *Implementation*: Include content hash as idempotency key for deduplication

**R008: Embedding Generation Failures**
- *Risk*: API calls to embedding service fail or timeout
- *Effect*: Strategies lack vector representation, affecting retrieval completeness
- *Mitigation*: Add retry/backoff logic and validate input length before API calls
- *Fallback*: Quarantine permanently failed embeddings for manual review

**R009: Regulatory Validation Errors**
- *Risk*: Valid strategies incorrectly rejected or invalid strategies approved
- *Effect*: Underserved coverage or harmful suggestions entering user flow
- *Mitigation*: Agent post-processing step with guardrails and validation rules
- *Monitoring*: Track validation rejection rates and implement manual audit hooks

**R010: Buffer Management Issues**
- *Risk*: Orphaned entries cause unbounded growth and storage bloat
- *Effect*: Database bloat, increased storage costs, degraded performance
- *Mitigation*: Explicit cleanup of buffer rows upon successful processing
- *Implementation*: Add expires_at field with TTL cleanup via scheduled jobs

## Performance Considerations

### Response Time Optimization
- **Target**: <30 seconds end-to-end
- **Parallel Processing**: Concurrent web searches and vector queries
- **Caching Strategy**: 5-minute TTL for web search results
- **Database Optimization**: Constraint-based pre-filtering before vector search

### Scalability Planning
- **Concurrent Users**: Support 10 simultaneous strategy generation requests
- **Database Scaling**: Horizontal read replicas for vector similarity queries
- **LLM Rate Limits**: Queue management for OpenAI API calls
- **Memory Management**: Efficient state handling in Python workflow

### Cost Optimization
- **LLM Token Efficiency**: Optimized prompts to minimize token usage
- **Web Search Limits**: 3 queries per optimization type with result caching
- **Vector Storage**: Efficient embedding models (text-embedding-3-small)
- **Database Queries**: Optimized JOINs and constraint filtering

## Testing Strategy

### Component Testing
1. **StrategyMCP Tool Testing**
   - Mock Tavily API responses for consistent testing
   - Vector similarity search validation with known embeddings
   - Constraint-to-query transformation accuracy

2. **StrategyCreator Agent Testing**
   - 4-strategy generation consistency validation
   - LLM scoring accuracy with known test cases
   - Output format compliance testing

3. **RegulatoryAgent Testing**
   - Compliance validation with mock regulatory scenarios
   - Confidence scoring accuracy assessment
   - Audit trail completeness verification

4. **StrategyMemoryLiteWorkflow Testing**
   - Buffer-based workflow operations with test data
   - Dual scoring system functionality
   - Vector embedding consistency

### Integration Testing
- **End-to-End Workflow**: Complete buffer-based workflow execution
- **Error Handling**: Component failure propagation
- **Performance Benchmarking**: <30 second requirement validation
- **External Service Integration**: Real API testing in staging

### Acceptance Testing
- **Strategy Quality**: Healthcare expert review of generated strategies
- **Regulatory Compliance**: Legal team validation of compliance logic
- **User Experience**: Healthcare consumer feedback on strategy clarity
- **Performance**: Load testing with concurrent requests

## Observability & Monitoring

### Structured Logging
- **Per-Strategy Tracking**: Emit structured logs per strategy_id with stage, status, latency
- **Component Logging**: Generator, validator, embedding stages with performance metrics
- **Error Tracking**: Failure modes, retry attempts, and resolution paths
- **Audit Trail**: Complete request lifecycle for compliance and debugging

### Logging Infrastructure for Future Monitoring
- **Structured Logging**: JSON format with consistent fields for downstream analysis
- **Metric Emission**: Log key performance indicators for future dashboard creation
- **Event Tracking**: Strategy lifecycle events for operational visibility
- **Error Classification**: Categorized error logging for pattern analysis

## Security & Compliance

### Data Protection
- **Encryption in Transit**: HTTPS for all external API calls
- **Access Controls**: RLS policies for strategy data protection
- **Audit Trail**: Complete logging of strategy generation and validation
- **Input Sanitization**: Validation of all plan constraints and user inputs
- **Content Validation**: Guardrails to prevent hallucinated PII or harmful recommendations

### Healthcare Compliance
- **HIPAA Considerations**: No PHI storage in strategy metadata
- **Regulatory Accuracy**: Audit trail for compliance decisions with manual review hooks
- **Data Retention**: Configurable retention policies for strategy data
- **Access Logging**: Complete audit trail for regulatory review
- **Quality Assurance**: Regular strategy evaluation and quality score monitoring

## Next Steps

This RFC002 establishes the technical architecture for the simplified Strategy Evaluation & Validation System MVP. The next document, **TODO002.md**, will provide the implementation breakdown with:

- Streamlined development tasks focused on prompt engineering
- Simplified component integration without complex phase tracking
- Direct Supabase SDK implementation patterns
- LLM-first testing strategies with reduced algorithmic complexity
- MVP deployment approach prioritizing speed over comprehensive features

The implementation will emphasize rapid development through LLM capabilities, semantic search, and proven architectural patterns rather than complex custom algorithms.
# CONTEXT.md

## ğŸ“Œ Core Product Context

This feature is a **post-output validation and security enforcement layer** in the Accessa chat agent pipeline. Its purpose is to ensure **all outputs remain strictly aligned with the requesting userâ€™s personal data and permissions**. It acts as a final gate to prevent data leakage, prompt injection artifacts, and unauthorized information disclosure.

The output is expected to be a **summarized, user-friendly response** generated by downstream workflows, which may include benefits explanations, form drafts, eligibility logic, or user-specific instructions. This module ensures that **only content grounded in the userâ€™s uploaded documents, stored profile, or derived eligibility** is passed back to the user.

---

## ğŸ§­ Intended Behavior

- **Allow**: User-specific summaries grounded in verified inputs.
- **Block/Flag**: Any content that:
  - Mentions another userâ€™s name, provider, or information.
  - Refers to internal implementation details (e.g., agent names, config steps).
  - Contains non-user-facing meta or raw model hallucinations.
  - Makes diagnostic, legal, or prescriptive claims that werenâ€™t explicitly sourced.

---

## ğŸ§ª Detection & Enforcement

- **Vector similarity check** between generated output and user-permitted documents or stored embeddings.
- **Pattern detection** for internal implementation leaks (e.g., `[AgentX]`, `[DEBUG]`, credentials, or system artifacts).
- **Risk scoring threshold** (e.g., 0.8+ match confidence to allow output).
- **Intervention actions**:
  - Redact or replace flagged text (optional, Phase 2+).
  - Block response and notify the user: â€œThis response could not be safely generated.â€
  - Log flagged output for admin review.
  - Rate-limit or restrict further output from the same input if abuse is suspected.

---

## ğŸ¯ Design Considerations

### Edge Cases
- Output refers to ambiguous entities (e.g., "your doctor") that might not be verified.
- Output structure mirrors user-uploaded content but is altered subtlyâ€”could still be a leak.
- Shared device or profile situation: multiple household members using one account.

### Constraints
- Must run with **low latency** to maintain responsive UX.
- Must not require outbound calls during enforcement (assume in-memory vector search or cached context).
- Initial implementation must avoid overblocking common safe outputs (false positives).

### Integration Points
- Receives structured summary output from downstream chat summarization agent.
- Has access to:
  - User profile
  - Uploaded document embeddings
  - Allowlist of permitted facts/terms
- Sends decision to:
  - Final output renderer
  - Admin flagging log system
  - Optional notification system

---

## â“ Open Questions

- Should redacted versions be shown with explanations (â€œSome content was removed for your privacyâ€)?
- Will we allow user overrides with warnings, or is this hard-blocked?
- Do we need versioning for flagged outputs for potential future appeal or audit?
- How do we handle multilingual inputs/outputs in this check?

---

## ğŸ”’ Security and Trust Goals

- Eliminate chance of LLM hallucinations introducing **non-user-grounded information**.
- Prevent internal agent or config information from surfacing to the user.
- Maintain HIPAA and PHI compliance by default, not post-facto.

---

## MVP Scope

- Basic vector similarity check and hard block at high-risk threshold.
- No redaction or partial output recovery.
- No admin review UI yet â€” just structured logs.

---

**Next step: move into â€œGoals and Non-goals.â€ Prompt me when ready.**
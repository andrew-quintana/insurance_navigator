{
  "agent_name": "Prompt Security",
  "fmea_entries": [
    {
      "function": "Detect prompt injection",
      "failure_mode": "Fails to detect jailbreak",
      "effect": "System instructions overridden, unsafe behavior",
      "severity": 9,
      "cause": "Prompt includes explicit override of system prompt",
      "occurrence": 4,
      "current_controls": "System prompt anchoring",
      "detection": 3,
      "rpn": 324,
      "recommended_action": "Inject adversarial jailbreaks during eval",
      "risk_level": "high"
    },
    {
      "function": "Detect prompt injection",
      "failure_mode": "Fails to detect instruction override",
      "effect": "System role redefined",
      "severity": 8,
      "cause": "Prompt redefines assistant persona or task",
      "occurrence": 4,
      "current_controls": "Hard-coded persona guardrails",
      "detection": 3,
      "rpn": 288,
      "recommended_action": "Detect role-switch instructions and enforce prefix",
      "risk_level": "high"
    },
    {
      "function": "Detect prompt injection",
      "failure_mode": "Fails to detect prompt leakage request",
      "effect": "Model reveals hidden context or system prompt",
      "severity": 9,
      "cause": "Prompt asks to repeat all instructions",
      "occurrence": 3,
      "current_controls": "Leakage string matcher",
      "detection": 3,
      "rpn": 243,
      "recommended_action": "Block meta-prompts requesting system disclosure",
      "risk_level": "high"
    },
    {
      "function": "Detect prompt injection",
      "failure_mode": "Fails to detect role hijack",
      "effect": "Model adopts attacker-defined behavior",
      "severity": 9,
      "cause": "Attacker redefines assistant persona mid-prompt",
      "occurrence": 4,
      "current_controls": "Token classifier for role-switching",
      "detection": 3,
      "rpn": 324,
      "recommended_action": "Use conversational memory to verify persistent persona",
      "risk_level": "high"
    },
    {
      "function": "Detect prompt injection",
      "failure_mode": "Fails to detect obfuscation",
      "effect": "Filtered word evaded via misspelling or encoding",
      "severity": 8,
      "cause": "Misspellings or homoglyphs bypass filter",
      "occurrence": 5,
      "current_controls": "Regex/embedding similarity filters",
      "detection": 4,
      "rpn": 640,
      "recommended_action": "Use adversarial noise simulation in eval",
      "risk_level": "critical"
    },
    {
      "function": "Detect prompt injection",
      "failure_mode": "Fails to detect payload splitting",
      "effect": "Prompt reassembled to act maliciously",
      "severity": 8,
      "cause": "Parts of prompt look benign alone",
      "occurrence": 3,
      "current_controls": "Contextual analysis limited to one line",
      "detection": 4,
      "rpn": 384,
      "recommended_action": "Add span-wide coherence checks",
      "risk_level": "high"
    },
    {
      "function": "Detect prompt injection",
      "failure_mode": "Fails to detect code injection",
      "effect": "Model executes or explains malicious code",
      "severity": 9,
      "cause": "Malicious script embedded in markdown/code block",
      "occurrence": 4,
      "current_controls": "Code block tokenizer",
      "detection": 4,
      "rpn": 576,
      "recommended_action": "Scan markdown/code for executable patterns",
      "risk_level": "critical"
    },
    {
      "function": "Detect prompt injection",
      "failure_mode": "Fails to detect multi-turn misdirection",
      "effect": "Safe intro primes unsafe follow-up to bypass check",
      "severity": 8,
      "cause": "Contextual divergence not flagged",
      "occurrence": 3,
      "current_controls": "One-shot prompt analyzer",
      "detection": 5,
      "rpn": 600,
      "recommended_action": "Add dialogue history consistency scoring",
      "risk_level": "critical"
    },
    {
      "function": "Detect indirect prompt injection",
      "failure_mode": "Fails to detect web content injection",
      "effect": "Model executes third-party prompt from web",
      "severity": 9,
      "cause": "Untrusted source contains injected prompt",
      "occurrence": 3,
      "current_controls": "HTML parser and scrubber",
      "detection": 3,
      "rpn": 243,
      "recommended_action": "DOM-level validation of external content",
      "risk_level": "high"
    },
    {
      "function": "Detect indirect prompt injection",
      "failure_mode": "Fails to detect document injection",
      "effect": "Prompt hidden in uploaded document text",
      "severity": 9,
      "cause": "Invisible/embedded content not parsed or validated",
      "occurrence": 3,
      "current_controls": "Basic text extractors",
      "detection": 3,
      "rpn": 243,
      "recommended_action": "Use OCR, hidden field scrubber",
      "risk_level": "high"
    },
    {
      "function": "Detect indirect prompt injection",
      "failure_mode": "Fails to detect email injection",
      "effect": "Malicious instructions embedded in email content",
      "severity": 8,
      "cause": "Quoted message not cleaned",
      "occurrence": 3,
      "current_controls": "Email pre-filter",
      "detection": 4,
      "rpn": 384,
      "recommended_action": "Strip common injection vectors from summaries",
      "risk_level": "high"
    },
    {
      "function": "Detect indirect prompt injection",
      "failure_mode": "Fails to detect cross-agent prompt propagation",
      "effect": "Unsafe prompt spreads downstream",
      "severity": 9,
      "cause": "Output of one agent becomes prompt for another",
      "occurrence": 4,
      "current_controls": "No output provenance tracking",
      "detection": 3,
      "rpn": 324,
      "recommended_action": "Trace prompt provenance through agent chain",
      "risk_level": "high"
    },
    {
      "function": "Detect prompt manipulation effects",
      "failure_mode": "Fails to detect instruction reversal",
      "effect": "LLM does opposite of expected task",
      "severity": 8,
      "cause": "Negation or adversarial phrasing",
      "occurrence": 4,
      "current_controls": "Command intent validation",
      "detection": 3,
      "rpn": 288,
      "recommended_action": "Verify intent match between prompt and output",
      "risk_level": "high"
    },
    {
      "function": "Detect prompt manipulation effects",
      "failure_mode": "Fails to detect self-modifying behavior",
      "effect": "LLM updates its own system instructions",
      "severity": 9,
      "cause": "Reinforcement or looping instruction",
      "occurrence": 3,
      "current_controls": "Prompt immutability layer",
      "detection": 3,
      "rpn": 243,
      "recommended_action": "Freeze system prompts per request lifecycle",
      "risk_level": "high"
    },
    {
      "function": "Detect prompt manipulation effects",
      "failure_mode": "Fails to detect sensitive data leakage",
      "effect": "LLM leaks credentials or private data",
      "severity": 10,
      "cause": "Prior context or memory leak",
      "occurrence": 3,
      "current_controls": "Redaction, no-memory mode",
      "detection": 3,
      "rpn": 270,
      "recommended_action": "Mask all context from prior interactions",
      "risk_level": "critical"
    },
    {
      "function": "Detect unsafe content",
      "failure_mode": "Fails to block hate speech",
      "effect": "Model outputs discriminatory language; reputational harm",
      "severity": 9,
      "cause": "Coded or less explicit hate phrases bypass filters",
      "occurrence": 4,
      "current_controls": "Basic moderation API and wordlist",
      "detection": 5,
      "rpn": 900,
      "recommended_action": "Use transformer-based bias detection + context filter",
      "risk_level": "critical"
    },
    {
      "function": "Detect unsafe content",
      "failure_mode": "Fails to block sexual content",
      "effect": "Sexually inappropriate output generated",
      "severity": 9,
      "cause": "Suggestive or euphemistic language not flagged",
      "occurrence": 4,
      "current_controls": "Content moderation API",
      "detection": 4,
      "rpn": 576,
      "recommended_action": "Add phrase embedding similarity filter to known patterns",
      "risk_level": "critical"
    },
    {
      "function": "Detect unsafe content",
      "failure_mode": "Fails to block violent content",
      "effect": "AI outputs graphic or instructional violent content",
      "severity": 9,
      "cause": "Violent descriptions framed as fiction evade checks",
      "occurrence": 4,
      "current_controls": "Text classifier and keyword flags",
      "detection": 4,
      "rpn": 576,
      "recommended_action": "Role-conditioned filtering on fictional requests",
      "risk_level": "critical"
    },
    {
      "function": "Detect unsafe content",
      "failure_mode": "Fails to block self-harm or suicide content",
      "effect": "Harm to users or enabling dangerous behavior",
      "severity": 10,
      "cause": "Suicidal ideation phrased as informational query",
      "occurrence": 3,
      "current_controls": "Self-harm classifier and escalation rule",
      "detection": 4,
      "rpn": 480,
      "recommended_action": "Add real-time safety signal scoring for known phrases",
      "risk_level": "critical"
    },
    {
      "function": "Detect unsafe content",
      "failure_mode": "Fails to block misinformation or health disinfo",
      "effect": "User misled on medical decisions or coverage options",
      "severity": 8,
      "cause": "Misinformation mimics legitimate query",
      "occurrence": 4,
      "current_controls": "Medical knowledge base checks",
      "detection": 4,
      "rpn": 512,
      "recommended_action": "Verify against trusted medical and insurance databases",
      "risk_level": "high"
    },
    {
      "function": "Detect unsafe content",
      "failure_mode": "Fails to block fraud or scam content",
      "effect": "Model helps generate phishing, impersonation, or fraud scripts",
      "severity": 9,
      "cause": "Prompt mimics customer service language",
      "occurrence": 3,
      "current_controls": "Fraud phrase detection",
      "detection": 4,
      "rpn": 432,
      "recommended_action": "Adversarial training on scam phrasing structures",
      "risk_level": "high"
    },
    {
      "function": "Detect unsafe content",
      "failure_mode": "Fails to block child exploitation language",
      "effect": "Legal violation and catastrophic brand/reputational risk",
      "severity": 10,
      "cause": "Suggestive but vague language passes through",
      "occurrence": 2,
      "current_controls": "String match and reporting escalation",
      "detection": 3,
      "rpn": 180,
      "recommended_action": "Use enhanced semantic and phrase safety checks",
      "risk_level": "critical"
    },
    {
      "function": "Detect unsafe content",
      "failure_mode": "Fails to detect political misinformation or propaganda",
      "effect": "Spread of disinformation or incitement",
      "severity": 8,
      "cause": "Polarizing or biased framing mimics factual tone",
      "occurrence": 4,
      "current_controls": "Fact checker API fallback",
      "detection": 4,
      "rpn": 512,
      "recommended_action": "Apply fact confidence scoring before answer generation",
      "risk_level": "high"
    },
    {
      "function": "Detect unsafe content",
      "failure_mode": "Fails to detect copyright-infringing requests",
      "effect": "Model generates protected material",
      "severity": 7,
      "cause": "Familiarity with popular media content triggers output",
      "occurrence": 4,
      "current_controls": "Prompt length + named entity check",
      "detection": 4,
      "rpn": 448,
      "recommended_action": "Entity match suppression for protected brands/scripts",
      "risk_level": "medium"
    },
    {
      "function": "Detect unsafe content",
      "failure_mode": "Fails to block radicalization or extremism content",
      "effect": "Model supports calls to violence or extremist content",
      "severity": 10,
      "cause": "Subcultural references or indirect calls go undetected",
      "occurrence": 3,
      "current_controls": "Hate group phrase list",
      "detection": 4,
      "rpn": 480,
      "recommended_action": "Cross-train on extremist manifesto fragments",
      "risk_level": "critical"
    },
    {
      "function": "Detect unsafe content",
      "failure_mode": "Fails to flag irrelevant domain content",
      "effect": "Wastes compute, confuses user with unrelated topics",
      "severity": 5,
      "cause": "Off-topic prompt accepted (e.g., cooking tips)",
      "occurrence": 6,
      "current_controls": "Domain classifier (manual)",
      "detection": 4,
      "rpn": 480,
      "recommended_action": "Train relevance filter on insurance/medical domains",
      "risk_level": "medium"
    },
    {
      "function": "Detect unsafe content",
      "failure_mode": "Fails to reject entertainment or personal queries",
      "effect": "Misaligned UX and inconsistent responses",
      "severity": 4,
      "cause": "Generalist assistant expectations override medical context",
      "occurrence": 5,
      "current_controls": "Scope boundaries in prompt instructions",
      "detection": 4,
      "rpn": 320,
      "recommended_action": "Hard limit prompts to scoped NPI/insurance/medical intent",
      "risk_level": "medium"
    },
    {
      "function": "Sanitize content",
      "failure_mode": "Removes benign intent or important task elements",
      "effect": "User's query misunderstood or rejected",
      "severity": 5,
      "cause": "Overzealous filtering logic",
      "occurrence": 6,
      "current_controls": "Heuristic threshold for filtering scope",
      "detection": 5,
      "rpn": 750,
      "recommended_action": "Add semantic diff check to preserve intent during sanitization",
      "risk_level": "high"
    },
    {
      "function": "Flag threats",
      "failure_mode": "High-risk prompt not logged or escalated",
      "effect": "Loss of traceability and threat monitoring",
      "severity": 5,
      "cause": "Logging bug or low confidence threshold",
      "occurrence": 4,
      "current_controls": "Logging layer with severity tagging",
      "detection": 3,
      "rpn": 300,
      "recommended_action": "Raise alert level for undefined sanitization behaviors",
      "risk_level": "medium"
    },
    {
      "function": "Allow safe input",
      "failure_mode": "Incorrectly blocks normal queries",
      "effect": "Prevents guide creation, user friction",
      "severity": 4,
      "cause": "Misclassified token or context mismatch",
      "occurrence": 6,
      "current_controls": "Prompt review loop via feedback",
      "detection": 5,
      "rpn": 480,
      "recommended_action": "Use user feedback loop to whitelist common false positives",
      "risk_level": "medium"
    }
  ],
  "metadata": {
    "version": "1.0",
    "last_updated": "2025-05-08"
  }
}
#!/usr/bin/env python3
"""
Resolve Processing Issues
Immediate fixes for the queue processing problems:
1. Clean up stuck jobs
2. Reset documents to proper status
3. Provide action plan for doc-parser
"""

import asyncio
import asyncpg
from datetime import datetime, timezone

# Configuration
DATABASE_URL = 'postgresql://postgres.jhrespvvhbnloxrieycf:beqhar-qincyg-Syxxi8@aws-0-us-west-1.pooler.supabase.com:6543/postgres'

async def main():
    """Resolve processing issues immediately"""
    print("üîß Resolving Processing Issues")
    print("=" * 50)
    
    conn = None
    try:
        # Connect to database
        conn = await asyncpg.connect(DATABASE_URL, server_settings={'jit': 'off'}, statement_cache_size=0)
        
        # Step 1: Clean up stuck jobs
        await cleanup_stuck_jobs(conn)
        
        # Step 2: Reset document statuses
        await reset_document_statuses(conn)
        
        # Step 3: Provide action plan
        await provide_action_plan()
        
        # Step 4: Final status check
        await final_status_check(conn)
        
        print("\n‚úÖ Immediate processing issues resolved!")
        
    except Exception as e:
        print(f"‚ùå Resolution failed: {e}")
        import traceback
        traceback.print_exc()
    finally:
        if conn:
            await conn.close()

async def cleanup_stuck_jobs(conn):
    """Clean up all stuck jobs"""
    print("\nüßπ Step 1: Cleaning Up Stuck Jobs")
    print("-" * 40)
    
    # Find all running jobs (they're all stuck)
    stuck_jobs = await conn.fetch("""
        SELECT 
            pj.id, pj.document_id, d.original_filename,
            EXTRACT(EPOCH FROM (NOW() - pj.created_at)) / 60 as age_minutes
        FROM processing_jobs pj
        JOIN documents d ON pj.document_id = d.id
        WHERE pj.status = 'running'
    """)
    
    if stuck_jobs:
        print(f"üö® Found {len(stuck_jobs)} stuck jobs to clean up:")
        
        for job in stuck_jobs:
            print(f"   üìÑ {job['original_filename']} (stuck {job['age_minutes']:.1f}m)")
            
            # Mark as failed to allow retry when doc-parser is fixed
            await conn.execute("""
                UPDATE processing_jobs 
                SET 
                    status = 'failed',
                    error_message = 'Doc-parser unavailable - will retry when fixed',
                    updated_at = NOW()
                WHERE id = $1
            """, job['id'])
        
        print(f"   ‚úÖ All {len(stuck_jobs)} jobs marked as failed (will retry)")
    else:
        print("‚úÖ No stuck jobs found")

async def reset_document_statuses(conn):
    """Reset document statuses to reflect reality"""
    print("\nüìÑ Step 2: Resetting Document Statuses")
    print("-" * 40)
    
    # Reset documents that are stuck in 'parsing' status
    parsing_docs = await conn.fetch("""
        SELECT id, original_filename, status
        FROM documents 
        WHERE status = 'parsing'
    """)
    
    if parsing_docs:
        print(f"üìã Found {len(parsing_docs)} documents stuck in 'parsing' status:")
        
        for doc in parsing_docs:
            print(f"   üìÑ {doc['original_filename']}")
            
            # Reset to pending so they can be reprocessed
            await conn.execute("""
                UPDATE documents 
                SET 
                    status = 'pending',
                    progress_percentage = 0,
                    updated_at = NOW()
                WHERE id = $1
            """, doc['id'])
        
        print(f"   ‚úÖ Reset {len(parsing_docs)} documents to 'pending' status")
    else:
        print("‚úÖ No documents stuck in parsing status")

async def provide_action_plan():
    """Provide clear action plan for fixing doc-parser"""
    print("\nüìã Step 3: Action Plan for Complete Fix")
    print("-" * 40)
    
    print("üéØ Critical: Fix Doc-Parser Edge Function")
    print()
    
    print("üìç Issue Identified:")
    print("   ‚Ä¢ Doc-parser edge function is not deployed or accessible")
    print("   ‚Ä¢ When accessible, it fails to download files from storage")
    print("   ‚Ä¢ This blocks all document processing")
    print()
    
    print("üîß Required Actions:")
    print()
    
    print("   1. üöÄ Deploy Doc-Parser Edge Function:")
    print("      ‚Ä¢ Check Supabase Dashboard ‚Üí Edge Functions")
    print("      ‚Ä¢ Ensure 'doc-parser' function is deployed")
    print("      ‚Ä¢ If not deployed: supabase functions deploy doc-parser")
    print()
    
    print("   2. üîë Set Required Environment Variables:")
    print("      ‚Ä¢ In Supabase Dashboard ‚Üí Edge Functions ‚Üí doc-parser ‚Üí Settings")
    print("      ‚Ä¢ Set these variables:")
    print("        - OPENAI_API_KEY: [your OpenAI key]")
    print("        - LLAMAPARSE_API_KEY: [your LlamaParse key]")
    print("        - CUSTOM_SERVICE_ROLE_KEY: [the service role key we added]")
    print()
    
    print("   3. üîó Verify File Access:")
    print("      ‚Ä¢ Doc-parser needs to access Supabase Storage")
    print("      ‚Ä¢ Check storage bucket permissions")
    print("      ‚Ä¢ Verify service role can read from 'raw_documents' bucket")
    print()
    
    print("   4. üß™ Test Edge Function:")
    print("      ‚Ä¢ Use Supabase Dashboard ‚Üí Edge Functions ‚Üí doc-parser ‚Üí Invoke")
    print("      ‚Ä¢ Test with a document ID and storage path")
    print()
    
    print("üöÄ Once Doc-Parser is Fixed:")
    print("   ‚Ä¢ Failed jobs will automatically retry")
    print("   ‚Ä¢ Pending documents will be processed")
    print("   ‚Ä¢ Queue will resume normal operation")

async def final_status_check(conn):
    """Check final status after cleanup"""
    print("\nüìä Step 4: Final Status Check")
    print("-" * 40)
    
    # Check current queue state
    queue_stats = await conn.fetch("""
        SELECT status, COUNT(*) as count
        FROM processing_jobs
        WHERE created_at > NOW() - INTERVAL '1 hour'
        GROUP BY status
        ORDER BY count DESC
    """)
    
    print("üìã Processing Jobs Status:")
    for stat in queue_stats:
        print(f"   {stat['status']}: {stat['count']} jobs")
    
    # Check document status
    doc_stats = await conn.fetch("""
        SELECT status, COUNT(*) as count
        FROM documents 
        GROUP BY status
        ORDER BY count DESC
    """)
    
    print(f"\nüìÑ Document Status:")
    for stat in doc_stats:
        print(f"   {stat['status']}: {stat['count']} documents")
    
    # Count pending jobs ready for retry
    pending_jobs = await conn.fetch('SELECT * FROM get_pending_jobs(10)')
    print(f"\n‚è≥ Pending jobs ready for processing: {len(pending_jobs)}")
    
    print(f"\nüí° Next Steps:")
    print(f"   1. Fix doc-parser edge function deployment")
    print(f"   2. Set required environment variables")
    print(f"   3. Test with: python test_queue_processing_only.py")
    print(f"   4. Monitor with: python check_processing_jobs_status.py")

if __name__ == "__main__":
    asyncio.run(main()) 